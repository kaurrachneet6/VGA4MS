{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gait Video Study \n",
    "### Traditional ML algorithms on task generalization framework 1: train on walking (W) and test on walking while talking (WT) to classify HOA/MS/PD strides and subjects \n",
    "#### Remember to add the original count of frames in a single stride (before down sampling via smoothing) for each stride as an additional artificial feature to add information about speed of the subject to the model\n",
    "\n",
    "1. Save the optimal hyperparameters, confusion matrices and ROC curves for each algorithm.\n",
    "2. Make sure to not use x, y, z, confidence = 0, 0, 0, 0 as points for the model since they are simply missing values and not data points, so make sure to treat them before inputting to model \n",
    "3. Make sure to normalize (mean substract) the features before we feed them to the model.\n",
    "4. We use the summary statistics as range, CoV and asymmetry between the right and left limbs as the features to input to the traditional models requiring fixed size 1D input for each training/testing set sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33 subject in total (~10 per group) \n",
    "# 4500 strides - 2000 strides - 200 groups for 10 strides per group\n",
    "# STRIDE - 20*36 - MEAN SUBSTRACTION --- BATCH NORM. \n",
    "# 90 features - 36 Cov, 36 Range, 18 assymetry, 18 DEN\n",
    "# Z-SCORE \n",
    "# Default + Dimensionality reduction - 3D space\n",
    "# Try top 10 features \n",
    "# Subject generalization is where the overfitting issue is tested - If we get good results, that means we are not \n",
    "# overfitting \n",
    "\n",
    "#Check how is AUC 1 even when accurcay is low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>cohort</th>\n",
       "      <th>trial</th>\n",
       "      <th>scenario</th>\n",
       "      <th>video</th>\n",
       "      <th>PID</th>\n",
       "      <th>stride_number</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>label</th>\n",
       "      <th>right hip-x-CoV</th>\n",
       "      <th>...</th>\n",
       "      <th>ankle-z-asymmetry</th>\n",
       "      <th>heel-x-asymmetry</th>\n",
       "      <th>heel-y-asymmetry</th>\n",
       "      <th>heel-z-asymmetry</th>\n",
       "      <th>toe 1-x-asymmetry</th>\n",
       "      <th>toe 1-y-asymmetry</th>\n",
       "      <th>toe 1-z-asymmetry</th>\n",
       "      <th>toe 2-x-asymmetry</th>\n",
       "      <th>toe 2-y-asymmetry</th>\n",
       "      <th>toe 2-z-asymmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GVS_212_T_T1_1</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046077</td>\n",
       "      <td>...</td>\n",
       "      <td>14.426173</td>\n",
       "      <td>3.407379</td>\n",
       "      <td>10.662441</td>\n",
       "      <td>0.830365</td>\n",
       "      <td>0.502570</td>\n",
       "      <td>31.450487</td>\n",
       "      <td>8.644012</td>\n",
       "      <td>5.236678</td>\n",
       "      <td>31.182183</td>\n",
       "      <td>8.215725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GVS_212_T_T1_2</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.360847</td>\n",
       "      <td>5.155307</td>\n",
       "      <td>11.363806</td>\n",
       "      <td>4.333776</td>\n",
       "      <td>1.025647</td>\n",
       "      <td>28.266400</td>\n",
       "      <td>2.671081</td>\n",
       "      <td>6.678294</td>\n",
       "      <td>15.058825</td>\n",
       "      <td>4.903579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GVS_212_T_T1_3</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034394</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341021</td>\n",
       "      <td>8.625363</td>\n",
       "      <td>7.159495</td>\n",
       "      <td>3.366152</td>\n",
       "      <td>1.759968</td>\n",
       "      <td>17.545787</td>\n",
       "      <td>5.921325</td>\n",
       "      <td>8.243491</td>\n",
       "      <td>9.578638</td>\n",
       "      <td>3.008162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GVS_212_T_T1_4</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028511</td>\n",
       "      <td>...</td>\n",
       "      <td>2.375934</td>\n",
       "      <td>6.728268</td>\n",
       "      <td>0.098235</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>0.541911</td>\n",
       "      <td>7.843339</td>\n",
       "      <td>4.279617</td>\n",
       "      <td>0.748023</td>\n",
       "      <td>19.471731</td>\n",
       "      <td>5.086056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GVS_212_T_T1_5</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>...</td>\n",
       "      <td>8.525816</td>\n",
       "      <td>1.775282</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>9.166863</td>\n",
       "      <td>1.354601</td>\n",
       "      <td>6.674183</td>\n",
       "      <td>8.479480</td>\n",
       "      <td>4.373622</td>\n",
       "      <td>0.315168</td>\n",
       "      <td>11.795593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              key cohort trial scenario         video  PID  stride_number  \\\n",
       "0  GVS_212_T_T1_1    HOA    BW     SLWT  GVS_212_T_T1  212              1   \n",
       "1  GVS_212_T_T1_2    HOA    BW     SLWT  GVS_212_T_T1  212              2   \n",
       "2  GVS_212_T_T1_3    HOA    BW     SLWT  GVS_212_T_T1  212              3   \n",
       "3  GVS_212_T_T1_4    HOA    BW     SLWT  GVS_212_T_T1  212              4   \n",
       "4  GVS_212_T_T1_5    HOA    BW     SLWT  GVS_212_T_T1  212              5   \n",
       "\n",
       "   frame_count  label  right hip-x-CoV  ...  ankle-z-asymmetry  \\\n",
       "0           46      0         0.046077  ...          14.426173   \n",
       "1           39      0         0.021528  ...           1.360847   \n",
       "2           56      0         0.034394  ...           1.341021   \n",
       "3           53      0         0.028511  ...           2.375934   \n",
       "4           44      0         0.025213  ...           8.525816   \n",
       "\n",
       "   heel-x-asymmetry  heel-y-asymmetry  heel-z-asymmetry  toe 1-x-asymmetry  \\\n",
       "0          3.407379         10.662441          0.830365           0.502570   \n",
       "1          5.155307         11.363806          4.333776           1.025647   \n",
       "2          8.625363          7.159495          3.366152           1.759968   \n",
       "3          6.728268          0.098235          0.999027           0.541911   \n",
       "4          1.775282          0.033210          9.166863           1.354601   \n",
       "\n",
       "   toe 1-y-asymmetry  toe 1-z-asymmetry  toe 2-x-asymmetry  toe 2-y-asymmetry  \\\n",
       "0          31.450487           8.644012           5.236678          31.182183   \n",
       "1          28.266400           2.671081           6.678294          15.058825   \n",
       "2          17.545787           5.921325           8.243491           9.578638   \n",
       "3           7.843339           4.279617           0.748023          19.471731   \n",
       "4           6.674183           8.479480           4.373622           0.315168   \n",
       "\n",
       "   toe 2-z-asymmetry  \n",
       "0           8.215725  \n",
       "1           4.903579  \n",
       "2           3.008162  \n",
       "3           5.086056  \n",
       "4          11.795593  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\Rachneet Kaur\\\\Box\\\\Gait Video Project\\\\GaitVideoData\\\\video\\\\'\n",
    "data_path = path+'traditional_methods_dataframe.csv'\n",
    "results_path = 'C:\\\\Users\\\\Rachneet Kaur\\\\Box\\Gait Video Project\\\\MLresults\\\\'\n",
    "\n",
    "data = pd.read_csv(data_path, index_col= 0)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_subjects_common_across_train_test(trial_train, trial_test):\n",
    "    '''\n",
    "    Since we need to implement pure task generalization framework, we must have same subjects across both training and testing trails \n",
    "    Hence, if there are some subjects that are present in the training set but not in the test set or vice versa, we eliminate those \n",
    "    subjects to have only common subjects across training and test sets. \n",
    "    Arguments: data subset for training and testing trial\n",
    "    Returns: training and testing subsets with common subjects \n",
    "    '''\n",
    "    \n",
    "    print ('Original number of subjects in training and test sets:', len(trial_train['PID'].unique()), len(trial_test['PID'].unique()))\n",
    "\n",
    "    #Try to use same subjects in trials W and WT for testing on same subjects we train on\n",
    "    print ('Subjects in test set, which are not in training set')\n",
    "    pids_missing_training = [] #PIDs missing in training set (trial W) but are present in the test set (trial WT)\n",
    "    for x in trial_test['PID'].unique():\n",
    "        if x not in trial_train['PID'].unique():\n",
    "            pids_missing_training.append(x)\n",
    "    print (pids_missing_training)\n",
    "\n",
    "    #Deleting the subjects from the test set that are missing in the training set \n",
    "    trial_test_reduced = trial_test.set_index('PID').drop(pids_missing_training).reset_index()\n",
    "\n",
    "    print ('Subjects in training set, which are not in test set')\n",
    "    pids_missing_test = [] #PIDs missing in test set (trial WT) but are present in the training set (trial W)\n",
    "    for x in trial_train['PID'].unique():\n",
    "        if x not in trial_test['PID'].unique():\n",
    "            pids_missing_test.append(x)\n",
    "    print (pids_missing_test)\n",
    "\n",
    "    #Deleting the subjects from the training set that are missing in the test set \n",
    "    trial_train_reduced = trial_train.set_index('PID').drop(pids_missing_test).reset_index()\n",
    "\n",
    "    print ('Number of subjects in training and test sets after reduction:', len(trial_train_reduced['PID'].unique()), \\\n",
    "           len(trial_test_reduced['PID'].unique()))\n",
    "    #Returning the dataframes where the training and testing set have common subjects \n",
    "    return trial_train_reduced, trial_test_reduced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data before ML methods \n",
    "#Take care that testing set is not used while normalizaing the training set, otherwise the train set indirectly contains \n",
    "#information about the test set\n",
    "def normalize(dataframe, n_type): \n",
    "    '''\n",
    "    Arguments: training set dataframe, type of normalization (z-score or min-max)\n",
    "    Returns: Computed mean and standard deviation for the training set \n",
    "    '''\n",
    "    col_names = list(dataframe.columns)\n",
    "    if (n_type == 'z'): #z-score normalization \n",
    "        mean = dataframe.mean()\n",
    "        sd = dataframe.std()\n",
    "    else: #min-max normalization\n",
    "        mean = dataframe.min()\n",
    "        sd = dataframe.max()-dataframe.min()\n",
    "    return mean, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(trainX, trainY, testX, testY, model_name = 'random_forest', framework = 'WtoWT'):\n",
    "    '''\n",
    "    Function to define and tune ML models \n",
    "    Arguments: training set: trainX, testX, testing set: testX, testY, model: model_name, framework\n",
    "    Returns: Prediction probabilities for HOA/MS/PD and stride and subject wise evaluation metrics \n",
    "    (Accuracy, Precision, Recall, F1 and AUC)\n",
    "    '''\n",
    "    trainY1 = trainY['label'] #Dropping the PID\n",
    "    \n",
    "    if(model_name == 'random_forest'): #Random Forest\n",
    "        grid = {\n",
    "       'n_estimators': [40,45,50],\\\n",
    "       'max_depth' : [15,20,25,None],\\\n",
    "       'class_weight': [None, 'balanced'],\\\n",
    "       'max_features': ['auto','sqrt','log2', None],\\\n",
    "       'min_samples_leaf':[1,2,0.1,0.05]\n",
    "        }\n",
    "        rf_grid = RandomForestClassifier(random_state=0)\n",
    "        grid_search = GridSearchCV(estimator = rf_grid, param_grid = grid, scoring='accuracy', n_jobs = 1, cv = 5)\n",
    "    \n",
    "    if(model_name == 'adaboost'): #Adaboost\n",
    "        ada_grid = AdaBoostClassifier(random_state=0)\n",
    "        grid = {\n",
    "        'n_estimators':[50, 75, 100, 125, 150],\\\n",
    "        'learning_rate':[0.01,.1, 1, 1.5, 2]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(ada_grid, param_grid = grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'kernel_svm'): #RBF SVM\n",
    "        svc_grid = SVC(kernel = 'rbf', probability=True, random_state=0)\n",
    "        grid = {\n",
    "        'gamma':[0.0001, 0.001, 0.1, 1, 10, ]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(svc_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "\n",
    "    if(model_name == 'gbm'): #GBM\n",
    "        gbm_grid = GradientBoostingClassifier(random_state=0)\n",
    "        grid = {\n",
    "        'learning_rate':[0.15,0.1,0.05], \\\n",
    "        'n_estimators':[50, 100, 150],\\\n",
    "        'max_depth':[2,4,7],\\\n",
    "        'min_samples_split':[2,4], \\\n",
    "        'min_samples_leaf':[1,3],\\\n",
    "        'max_features':[4, 5, 6]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(gbm_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name=='xgboost'): #Xgboost\n",
    "        xgb_grid = xgboost.XGBClassifier(random_state=0)\n",
    "        grid = {\n",
    "            'min_child_weight': [1, 5],\\\n",
    "            'gamma': [0.1, 0.5, 1, 1.5, 2],\\\n",
    "            'subsample': [0.6, 0.8, 1.0],\\\n",
    "            'colsample_bytree': [0.6, 0.8, 1.0],\\\n",
    "            'max_depth': [5, 7, 8]\n",
    "        }\n",
    "        grid_search = GridSearchCV(xgb_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'knn'): #KNN\n",
    "        knn_grid = KNeighborsClassifier()\n",
    "        grid = {\n",
    "            'n_neighbors': [1, 3, 4, 5, 10],\\\n",
    "            'p': [1, 2, 3, 4, 5]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(knn_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "        \n",
    "    if(model_name == 'decision_tree'): #Decision Tree\n",
    "        dec_grid = DecisionTreeClassifier(random_state=0)\n",
    "        grid = {\n",
    "            'min_samples_split': range(2, 50),\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(dec_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'linear_svm'): #Linear SVM\n",
    "        lsvm_grid = LinearSVC(random_state=0)\n",
    "        grid = {\n",
    "            'loss': ['hinge','squared_hinge'],\\\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(lsvm_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "    \n",
    "    if(model_name == 'logistic_regression'): #Logistic regression\n",
    "        grid_search = LogisticRegression(random_state=0)\n",
    "    \n",
    "    if(model_name == 'mlp'):\n",
    "        mlp_grid = MLPClassifier(activation='relu', solver='adam', learning_rate = 'adaptive', learning_rate_init=0.001,\\\n",
    "                                                        shuffle=False, max_iter = 500, random_state = 0)\n",
    "        grid = {\n",
    "            'hidden_layer_sizes': [(128, 8, 8, 128, 32), (50, 50, 50, 50, 50, 50, 150, 100, 10), \n",
    "                                  (50, 50, 50, 50, 50, 60, 30, 20, 50), (50, 50, 50, 50, 50, 150, 10, 60, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 50, 10, 5), (50, 50, 50, 50, 50, 5, 50, 150, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 30, 50, 20), (50, 50, 50, 50, 10, 150, 20, 20, 30),\n",
    "                                  (50, 50, 50, 50, 30, 150, 100, 20, 100), (50, 50, 50, 50, 30, 5, 100, 20, 100),\n",
    "                                  (50, 50, 50, 50, 60, 50, 50, 60, 60), (50, 50, 50, 50, 20, 50, 60, 20, 20),\n",
    "                                  (50, 50, 50, 10, 50, 10, 150, 60, 150), (50, 50, 50, 10, 50, 150, 30, 150, 5),\n",
    "                                  (50, 50, 50, 10, 50, 20, 150, 5, 10), (50, 50, 50, 10, 150, 50, 20, 20, 100), \n",
    "                                  (50, 50, 50, 30, 100, 5, 30, 150, 30), (50, 50, 50, 50, 100, 150, 100, 200), \n",
    "                                  (50, 50, 50, 5, 5, 100, 100, 150), (50, 50, 5, 50, 200, 100, 150, 5), \n",
    "                                  (50, 50, 5, 5, 200, 100, 50, 30), (50, 50, 5, 10, 5, 200, 200, 10), \n",
    "                                  (50, 50, 5, 30, 5, 5, 50, 10), (50, 50, 5, 200, 50, 5, 5, 50), \n",
    "                                  (50, 50,50, 5, 5, 100, 100, 150), (5, 5, 5, 5, 5, 100, 50, 5, 50, 50), \n",
    "                                  (5, 5, 5, 5, 5, 100, 20, 100, 30, 30), (5, 5, 5, 5, 5, 20, 20, 5, 30, 100), \n",
    "                                  (5, 5, 5, 5, 5, 20, 20, 100, 10, 10), (5, 5, 5, 5, 10, 10, 30, 50, 10, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 30, 30, 30, 10), (5, 5, 5, 5, 10, 100, 50, 10, 50, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 20, 100, 30, 5), (5, 5, 5, 5, 30, 5, 20, 30, 100, 50), \n",
    "                                  (5, 5, 5, 5, 30, 100, 20, 50, 20, 30), (5, 5, 5, 5, 50, 30, 5, 50, 10, 100), \n",
    "                                  (21, 21, 7, 84, 21, 84, 84), (21, 21, 5, 42, 42, 7, 42), (21, 84, 7, 7, 7, 84, 5), \n",
    "                                  (21, 7, 84, 5, 5, 21, 120), (42, 5, 21, 21, 21, 5, 120), (42, 5, 42, 84, 7, 120, 84), \n",
    "                                  (50, 100, 10, 5, 100, 25), (10, 10, 25, 50, 25, 5), (50, 50, 50, 50, 50, 20, 30, 100, 60)]\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(mlp_grid, param_grid=grid, scoring='accuracy', n_jobs = 1, cv=5)\n",
    "        \n",
    "    grid_search.fit(trainX, trainY1) #Fitting on the training set to find the optimal hyperparameters \n",
    "#     print('best score: ', grid_search.best_score_)\n",
    "#     print('best_params: ', grid_search.best_params_, grid_search.best_index_)\n",
    "#     print('Mean cv accuracy on test set:', grid_search.cv_results_['mean_test_score'][grid_search.best_index_])\n",
    "#     print('Standard deviation on test set:' , grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
    "#     print('Mean cv accuracy on train set:', grid_search.cv_results_['mean_train_score'][grid_search.best_index_])\n",
    "#     print('Standard deviation on train set:', grid_search.cv_results_['std_train_score'][grid_search.best_index_])\n",
    "#     print('Test set performance:\\n')\n",
    "    person_wise_prob_for_roc, stride_person_metrics = evaluate(grid_search, testX, testY, framework, model_name)\n",
    "    return person_wise_prob_for_roc, stride_person_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, trueY, framework, model_name):\n",
    "    '''\n",
    "    Function to evaluate ML models and plot it's confusion matrix\n",
    "    Input: model, test set, true test set labels, framework name, model name\n",
    "    Computes the stride and subject wise test set evaluation metrics \n",
    "    Returns: Prediction probabilities for HOA/MS/PD and stride and subject wise evaluation metrics \n",
    "    (Accuracy, Precision, Recall, F1 and AUC)\n",
    "    '''\n",
    "    test_labels = trueY['label'] #Dropping the PID\n",
    "#     print ('Test labels', test_labels)\n",
    "    predictions = model.predict(test_features)\n",
    "#     print ('Predictions', predictions)\n",
    "    \n",
    "    #Stride wise metrics \n",
    "    acc = accuracy_score(test_labels, predictions)\n",
    "    #For multiclass predictions, we need to use marco/micro average\n",
    "    p = precision_score(test_labels, predictions, average='macro')  \n",
    "    r = recall_score(test_labels, predictions, average = 'macro')\n",
    "    f1 = f1_score(test_labels, predictions, average= 'macro')\n",
    "    \n",
    "    try:\n",
    "        prediction_prob = model.predict_proba(test_features) #Score of the class with greater label\n",
    "#         print ('Prediction Probability', model.predict_proba(test_features))\n",
    "        \n",
    "    except:\n",
    "        prediction_prob = model.best_estimator_._predict_proba_lr(test_features) #For linear SVM\n",
    "#         print ('Prediction Probability', model.best_estimator_._predict_proba_lr(test_features))\n",
    "    \n",
    "    #For computing the AUC, we would need prediction probabilities for all the 3 classes \n",
    "    auc = roc_auc_score(test_labels, prediction_prob, multi_class = 'ovo', average= 'macro')\n",
    "    print('Stride-based model performance: ', acc, p, r, f1, auc)\n",
    "    \n",
    "    #For computing person wise metrics \n",
    "    temp = copy.deepcopy(trueY) #True label for the stride \n",
    "    temp['pred'] = predictions #Predicted label for the stride \n",
    "    #Saving the stride wise true and predicted labels for calculating the stride wise confusion matrix for each model\n",
    "    temp.to_csv(results_path+ framework + '\\\\stride_wise_predictions_' + str(model_name) + '_' + framework + '.csv')\n",
    "    \n",
    "    x = temp.groupby('PID')['pred'].value_counts().unstack()\n",
    "    #Input for subject wise AUC is probabilities at columns [0, 1, 2]\n",
    "    proportion_strides_correct = x.divide(x.sum(axis = 1), axis = 0).fillna(0) \n",
    "    proportion_strides_correct['True Label'] = trueY.groupby('PID').first()\n",
    "    #Input for precision, recall and F1 score\n",
    "    proportion_strides_correct['Predicted Label'] = proportion_strides_correct[[0, 1, 2]].idxmax(axis = 1) \n",
    "    #Saving the person wise true and predicted labels for calculating the subject wise confusion matrix for each model\n",
    "    proportion_strides_correct.to_csv(results_path+ framework + '\\\\person_wise_predictions_' + \\\n",
    "                                      str(model_name) + '_' + framework + '.csv')\n",
    "    try:\n",
    "        print (model.best_estimator_)\n",
    "    except:\n",
    "        pass\n",
    "    #Person wise metrics \n",
    "    person_acc = accuracy_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'])\n",
    "    person_p = precision_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'], \\\n",
    "                               average = 'macro')\n",
    "    person_r = recall_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'], \\\n",
    "                            average = 'macro')\n",
    "    person_f1 = f1_score(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'], \\\n",
    "                         average = 'macro')\n",
    "    person_auc = roc_auc_score(proportion_strides_correct['True Label'], proportion_strides_correct[[0, 1, 2]], \\\n",
    "                               multi_class = 'ovo', average= 'macro')\n",
    "    print('Person-based model performance: ', person_acc, person_p, person_r, person_f1, person_auc)\n",
    "      \n",
    "    #Plotting and saving the subject wise confusion matrix \n",
    "    plt.figure()\n",
    "    confusion_matrix = pd.crosstab(proportion_strides_correct['True Label'], proportion_strides_correct['Predicted Label'], \\\n",
    "                                   rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
    "    sns.heatmap(confusion_matrix, annot=True, cmap=\"YlGnBu\")\n",
    "    plt.savefig(results_path + framework+'\\\\CFmatrix_task_generalize_' + framework + '_'+ ml_model+ '.png', dpi = 350)\n",
    "    plt.show()\n",
    "    return proportion_strides_correct[[0, 1, 2]], [acc, p, r, f1, auc, person_acc, person_p, person_r, person_f1, person_auc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set ROC curves for cohort prediction \n",
    "def plot_ROC(ml_models, testY, predicted_probs_person, framework):\n",
    "    '''\n",
    "    Function to plot the ROC curve for models given in ml_models list \n",
    "    Input: ml_models (name of models to plot the ROC for),  test_Y (true test set labels with PID), \n",
    "        predicted_probs_person (predicted test set probabilities for all 3 classes - HOA/MS/PD), framework (WtoWT / VBWtoVBWT)\n",
    "    Plots and saves the ROC curve with individual class-wise plots and micro/macro average plots \n",
    "    '''\n",
    "    n_classes = 3 #HOA/MS/PD\n",
    "    cohort = ['HOA', 'MS', 'PD']\n",
    "    ml_model_names = {'random_forest': 'RF', 'adaboost': 'Adaboost', 'kernel_svm': 'RBF SVM', 'gbm': 'GBM', \\\n",
    "                      'xgboost': 'Xgboost', 'knn': 'KNN', 'decision_tree': 'DT',  'linear_svm': 'LSVM', \n",
    "                 'logistic_regression': 'LR', 'mlp': 'MLP'}\n",
    "    #PID-wise true labels \n",
    "    person_true_labels = testY.groupby('PID').first()\n",
    "    #Binarizing/getting dummies for the true labels i.e. class 1 is represented as 0, 1, 0\n",
    "    person_true_labels_binarize = pd.get_dummies(person_true_labels.values.reshape(1, -1)[0])  \n",
    "\n",
    "    sns.despine(offset=0)\n",
    "    linestyles = ['-', '-', '-', '-.', '--', '-', '--', '-', '--']\n",
    "    colors = ['b', 'magenta', 'cyan', 'g',  'red', 'violet', 'lime', 'grey', 'pink']\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for idx, ml_model in enumerate(ml_models): #Plotting the ROCs for all models in ml_models list\n",
    "        fig, axes = plt.subplots(1, 1, sharex=True, sharey = True, figsize=(6, 4.5))\n",
    "        axes.plot([0, 1], [0, 1], linestyle='--', label='Majority (AUC = 0.5)', linewidth = 3, color = 'k')\n",
    "        # person-based prediction probabilities for class 0: HOA, 1: MS, 2: PD\n",
    "        model_probs = predicted_probs_person[[ml_model+'_HOA', ml_model+'_MS', ml_model+'_PD']]\n",
    "\n",
    "        for i in range(n_classes): #For 3 classes 0, 1, 2\n",
    "            fpr[i], tpr[i], _ = roc_curve(person_true_labels_binarize.iloc[:, i], model_probs.iloc[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i]) #Computing the AUC score for each class\n",
    "            #Plotting the ROCs for the three classes separately\n",
    "            axes.plot(fpr[i], tpr[i], label = cohort[i] +' ROC (AUC = '+ str(round(roc_auc[i], 3))\n",
    "                +')', linewidth = 3, alpha = 0.8, linestyle = linestyles[i], color = colors[i]) \n",
    "\n",
    "        # Compute micro-average ROC curve and ROC area (AUC)\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(person_true_labels_binarize.values.ravel(), model_probs.values.ravel())\n",
    "        #Micro average AUC of ROC value\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"]) \n",
    "        #Plotting the micro average ROC \n",
    "        axes.plot(fpr[\"micro\"], tpr[\"micro\"], label= 'micro average ROC (AUC = '+ str(round(roc_auc[\"micro\"], 3))\n",
    "                +')', linewidth = 3, alpha = 0.8, linestyle = linestyles[3], color = colors[3])\n",
    "\n",
    "        #Compute the macro-average ROC curve and AUC value\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)])) # First aggregate all false positive rates\n",
    "        mean_tpr = np.zeros_like(all_fpr) # Then interpolate all ROC curves at this points\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "        mean_tpr /= n_classes  # Finally average it and compute AUC\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        #Macro average AUC of ROC value \n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "        #Plotting the macro average AUC\n",
    "        axes.plot(fpr[\"macro\"], tpr[\"macro\"], label= 'macro average ROC (AUC = '+ str(round(roc_auc[\"macro\"], 3))\n",
    "            +')', linewidth = 3, alpha = 0.8, linestyle = linestyles[4], color = colors[4])\n",
    "\n",
    "        axes.set_ylabel('True Positive Rate')\n",
    "        axes.set_title('Task generalization '+framework + ' '+ ml_model_names[ml_model])\n",
    "        plt.legend()\n",
    "        # axes[1].legend(loc='upper center', bbox_to_anchor=(1.27, 1), ncol=1)\n",
    "\n",
    "        axes.set_xlabel('False Positive Rate')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(results_path + framework+'\\\\ROC_task_generalize_' + framework + '_'+ ml_model+ '.png', dpi = 350)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of subjects in training and test sets: 32 26\n",
      "Subjects in test set, which are not in training set\n",
      "[403]\n",
      "Subjects in training set, which are not in test set\n",
      "[312, 102, 112, 113, 115, 123, 124]\n",
      "Number of subjects in training and test sets after reduction: 25 25\n",
      "Training shape (1128, 91) (1128, 2)\n",
      "Testing shape (1142, 91) (1142, 2)\n",
      "Strides in training set:  1128\n",
      "HOA, MS and PD strides in training set:\n",
      " PD     453\n",
      "MS     341\n",
      "HOA    334\n",
      "Name: cohort, dtype: int64\n",
      "\n",
      "Strides in test set:  1142\n",
      "HOA, MS and PD strides in test set:\n",
      " PD     459\n",
      "HOA    351\n",
      "MS     332\n",
      "Name: cohort, dtype: int64\n",
      "Imbalance ratio (controls:MS:PD)= 1:X:Y\n",
      " PD     1.307692\n",
      "HOA    1.000000\n",
      "MS     0.945869\n",
      "Name: cohort, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Trial W for training \n",
    "trialW = data[data['scenario']=='W']\n",
    "#Trial WT for testing \n",
    "trialWT = data[data['scenario']=='WT']\n",
    "\n",
    "#Trial W and WT after making sure both training and testing sets have common subjects \n",
    "trialW_reduced, trialWT_reduced = keep_subjects_common_across_train_test(trialW, trialWT)\n",
    "# print ('Number of subjects in training and test sets after reduction:', len(trialW_reduced['PID'].unique()), \\\n",
    "#            len(trialWT_reduced['PID'].unique()))\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the training stride data\n",
    "trialW_reduced = shuffle(trialW_reduced, random_state = 0)\n",
    "trainX = trialW_reduced.drop(cols_to_drop, axis = 1)\n",
    "trainY = trialW_reduced[['PID', 'label']]\n",
    "print ('Training shape', trainX.shape, trainY.shape)\n",
    "\n",
    "#Shuffling the testing stride data \n",
    "trialWT_reduced = shuffle(trialWT_reduced, random_state = 0)\n",
    "testX = trialWT_reduced.drop(cols_to_drop, axis = 1)\n",
    "testY = trialWT_reduced[['PID', 'label']] #PID to compute person based metrics later \n",
    "print ('Testing shape', testX.shape, testY.shape)\n",
    "\n",
    "#Normalize according to z-score standardization\n",
    "norm_mean, norm_sd = normalize(trainX, 'z')\n",
    "trainX_norm = (trainX-norm_mean)/norm_sd\n",
    "testX_norm = (testX-norm_mean)/norm_sd\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in training set: ', len(trialW_reduced))\n",
    "print ('HOA, MS and PD strides in training set:\\n', trialW_reduced['cohort'].value_counts())\n",
    "\n",
    "#Test Set\n",
    "print('\\nStrides in test set: ', len(trialWT_reduced)) \n",
    "print ('HOA, MS and PD strides in test set:\\n', trialWT_reduced['cohort'].value_counts())\n",
    "print ('Imbalance ratio (controls:MS:PD)= 1:X:Y\\n', trialWT_reduced['cohort'].value_counts()/trialWT_reduced['cohort'].value_counts()['HOA'])\n",
    "\n",
    "framework = 'WtoWT' #Defining the task generalization framework of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>cohort</th>\n",
       "      <th>trial</th>\n",
       "      <th>scenario</th>\n",
       "      <th>PID</th>\n",
       "      <th>stride_number</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>label</th>\n",
       "      <th>right hip-x-CoV</th>\n",
       "      <th>right hip-y-CoV</th>\n",
       "      <th>...</th>\n",
       "      <th>ankle-z-asymmetry</th>\n",
       "      <th>heel-x-asymmetry</th>\n",
       "      <th>heel-y-asymmetry</th>\n",
       "      <th>heel-z-asymmetry</th>\n",
       "      <th>toe 1-x-asymmetry</th>\n",
       "      <th>toe 1-y-asymmetry</th>\n",
       "      <th>toe 1-z-asymmetry</th>\n",
       "      <th>toe 2-x-asymmetry</th>\n",
       "      <th>toe 2-y-asymmetry</th>\n",
       "      <th>toe 2-z-asymmetry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GVS_102_W_T1</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_112_W_T1</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_113_W_T1</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_115_W_T1</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_123_W_T1</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_124_W_T1</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_212_W_T2</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_213_W_T1</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_214_W_T1</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_215_W_T1</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_216_W_T2</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_217_W_T1</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_218_W_T2</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_219_W_T2</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_310_W_T1</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_311_W_T1</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_312_W_T2</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_313_W_T1</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_314_W_T1</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_318_W_T1</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_320_W_T1</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_321_W_T1</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_322_W_T2</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_323_W_T1</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_404_W_T2</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_404_W_T3</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_405_W_T1</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_405_W_T3</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_406_W_T2</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_407_W_T2</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_408_W_T2</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_409_W_T2</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_410_W_T1</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_411_W_T1</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GVS_411_W_T3</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              key  cohort  trial  scenario  PID  stride_number  frame_count  \\\n",
       "video                                                                         \n",
       "GVS_102_W_T1   90      90     90        90   90             90           90   \n",
       "GVS_112_W_T1   95      95     95        95   95             95           95   \n",
       "GVS_113_W_T1   57      57     57        57   57             57           57   \n",
       "GVS_115_W_T1   52      52     52        52   52             52           52   \n",
       "GVS_123_W_T1  118     118    118       118  118            118          118   \n",
       "GVS_124_W_T1   63      63     63        63   63             63           63   \n",
       "GVS_212_W_T2   44      44     44        44   44             44           44   \n",
       "GVS_213_W_T1   43      43     43        43   43             43           43   \n",
       "GVS_214_W_T1   38      38     38        38   38             38           38   \n",
       "GVS_215_W_T1   45      45     45        45   45             45           45   \n",
       "GVS_216_W_T2   40      40     40        40   40             40           40   \n",
       "GVS_217_W_T1   39      39     39        39   39             39           39   \n",
       "GVS_218_W_T2   45      45     45        45   45             45           45   \n",
       "GVS_219_W_T2   40      40     40        40   40             40           40   \n",
       "GVS_310_W_T1   41      41     41        41   41             41           41   \n",
       "GVS_311_W_T1   43      43     43        43   43             43           43   \n",
       "GVS_312_W_T2   48      48     48        48   48             48           48   \n",
       "GVS_313_W_T1   38      38     38        38   38             38           38   \n",
       "GVS_314_W_T1   38      38     38        38   38             38           38   \n",
       "GVS_318_W_T1   17      17     17        17   17             17           17   \n",
       "GVS_320_W_T1   45      45     45        45   45             45           45   \n",
       "GVS_321_W_T1   39      39     39        39   39             39           39   \n",
       "GVS_322_W_T2   40      40     40        40   40             40           40   \n",
       "GVS_323_W_T1   40      40     40        40   40             40           40   \n",
       "GVS_404_W_T2   41      41     41        41   41             41           41   \n",
       "GVS_404_W_T3   41      41     41        41   41             41           41   \n",
       "GVS_405_W_T1   41      41     41        41   41             41           41   \n",
       "GVS_405_W_T3   40      40     40        40   40             40           40   \n",
       "GVS_406_W_T2   44      44     44        44   44             44           44   \n",
       "GVS_407_W_T2   39      39     39        39   39             39           39   \n",
       "GVS_408_W_T2   44      44     44        44   44             44           44   \n",
       "GVS_409_W_T2   44      44     44        44   44             44           44   \n",
       "GVS_410_W_T1   41      41     41        41   41             41           41   \n",
       "GVS_411_W_T1   39      39     39        39   39             39           39   \n",
       "GVS_411_W_T3   39      39     39        39   39             39           39   \n",
       "\n",
       "              label  right hip-x-CoV  right hip-y-CoV  ...  ankle-z-asymmetry  \\\n",
       "video                                                  ...                      \n",
       "GVS_102_W_T1     90               90               90  ...                 90   \n",
       "GVS_112_W_T1     95               95               95  ...                 95   \n",
       "GVS_113_W_T1     57               57               57  ...                 57   \n",
       "GVS_115_W_T1     52               52               52  ...                 52   \n",
       "GVS_123_W_T1    118              118              118  ...                118   \n",
       "GVS_124_W_T1     63               63               63  ...                 63   \n",
       "GVS_212_W_T2     44               44               44  ...                 44   \n",
       "GVS_213_W_T1     43               43               43  ...                 43   \n",
       "GVS_214_W_T1     38               38               38  ...                 38   \n",
       "GVS_215_W_T1     45               45               45  ...                 45   \n",
       "GVS_216_W_T2     40               40               40  ...                 40   \n",
       "GVS_217_W_T1     39               39               39  ...                 39   \n",
       "GVS_218_W_T2     45               45               45  ...                 45   \n",
       "GVS_219_W_T2     40               40               40  ...                 40   \n",
       "GVS_310_W_T1     41               41               41  ...                 41   \n",
       "GVS_311_W_T1     43               43               43  ...                 43   \n",
       "GVS_312_W_T2     48               48               48  ...                 48   \n",
       "GVS_313_W_T1     38               38               38  ...                 38   \n",
       "GVS_314_W_T1     38               38               38  ...                 38   \n",
       "GVS_318_W_T1     17               17               17  ...                 17   \n",
       "GVS_320_W_T1     45               45               45  ...                 45   \n",
       "GVS_321_W_T1     39               39               39  ...                 39   \n",
       "GVS_322_W_T2     40               40               40  ...                 40   \n",
       "GVS_323_W_T1     40               40               40  ...                 40   \n",
       "GVS_404_W_T2     41               41               41  ...                 41   \n",
       "GVS_404_W_T3     41               41               41  ...                 41   \n",
       "GVS_405_W_T1     41               41               41  ...                 41   \n",
       "GVS_405_W_T3     40               40               40  ...                 40   \n",
       "GVS_406_W_T2     44               44               44  ...                 44   \n",
       "GVS_407_W_T2     39               39               39  ...                 39   \n",
       "GVS_408_W_T2     44               44               44  ...                 44   \n",
       "GVS_409_W_T2     44               44               44  ...                 44   \n",
       "GVS_410_W_T1     41               41               41  ...                 41   \n",
       "GVS_411_W_T1     39               39               39  ...                 39   \n",
       "GVS_411_W_T3     39               39               39  ...                 39   \n",
       "\n",
       "              heel-x-asymmetry  heel-y-asymmetry  heel-z-asymmetry  \\\n",
       "video                                                                \n",
       "GVS_102_W_T1                90                90                90   \n",
       "GVS_112_W_T1                95                95                95   \n",
       "GVS_113_W_T1                57                57                57   \n",
       "GVS_115_W_T1                52                52                52   \n",
       "GVS_123_W_T1               118               118               118   \n",
       "GVS_124_W_T1                63                63                63   \n",
       "GVS_212_W_T2                44                44                44   \n",
       "GVS_213_W_T1                43                43                43   \n",
       "GVS_214_W_T1                38                38                38   \n",
       "GVS_215_W_T1                45                45                45   \n",
       "GVS_216_W_T2                40                40                40   \n",
       "GVS_217_W_T1                39                39                39   \n",
       "GVS_218_W_T2                45                45                45   \n",
       "GVS_219_W_T2                40                40                40   \n",
       "GVS_310_W_T1                41                41                41   \n",
       "GVS_311_W_T1                43                43                43   \n",
       "GVS_312_W_T2                48                48                48   \n",
       "GVS_313_W_T1                38                38                38   \n",
       "GVS_314_W_T1                38                38                38   \n",
       "GVS_318_W_T1                17                17                17   \n",
       "GVS_320_W_T1                45                45                45   \n",
       "GVS_321_W_T1                39                39                39   \n",
       "GVS_322_W_T2                40                40                40   \n",
       "GVS_323_W_T1                40                40                40   \n",
       "GVS_404_W_T2                41                41                41   \n",
       "GVS_404_W_T3                41                41                41   \n",
       "GVS_405_W_T1                41                41                41   \n",
       "GVS_405_W_T3                40                40                40   \n",
       "GVS_406_W_T2                44                44                44   \n",
       "GVS_407_W_T2                39                39                39   \n",
       "GVS_408_W_T2                44                44                44   \n",
       "GVS_409_W_T2                44                44                44   \n",
       "GVS_410_W_T1                41                41                41   \n",
       "GVS_411_W_T1                39                39                39   \n",
       "GVS_411_W_T3                39                39                39   \n",
       "\n",
       "              toe 1-x-asymmetry  toe 1-y-asymmetry  toe 1-z-asymmetry  \\\n",
       "video                                                                   \n",
       "GVS_102_W_T1                 90                 90                 90   \n",
       "GVS_112_W_T1                 95                 95                 95   \n",
       "GVS_113_W_T1                 57                 57                 57   \n",
       "GVS_115_W_T1                 52                 52                 52   \n",
       "GVS_123_W_T1                118                118                118   \n",
       "GVS_124_W_T1                 63                 63                 63   \n",
       "GVS_212_W_T2                 44                 44                 44   \n",
       "GVS_213_W_T1                 43                 43                 43   \n",
       "GVS_214_W_T1                 38                 38                 38   \n",
       "GVS_215_W_T1                 45                 45                 45   \n",
       "GVS_216_W_T2                 40                 40                 40   \n",
       "GVS_217_W_T1                 39                 39                 39   \n",
       "GVS_218_W_T2                 45                 45                 45   \n",
       "GVS_219_W_T2                 40                 40                 40   \n",
       "GVS_310_W_T1                 41                 41                 41   \n",
       "GVS_311_W_T1                 43                 43                 43   \n",
       "GVS_312_W_T2                 48                 48                 48   \n",
       "GVS_313_W_T1                 38                 38                 38   \n",
       "GVS_314_W_T1                 38                 38                 38   \n",
       "GVS_318_W_T1                 17                 17                 17   \n",
       "GVS_320_W_T1                 45                 45                 45   \n",
       "GVS_321_W_T1                 39                 39                 39   \n",
       "GVS_322_W_T2                 40                 40                 40   \n",
       "GVS_323_W_T1                 40                 40                 40   \n",
       "GVS_404_W_T2                 41                 41                 41   \n",
       "GVS_404_W_T3                 41                 41                 41   \n",
       "GVS_405_W_T1                 41                 41                 41   \n",
       "GVS_405_W_T3                 40                 40                 40   \n",
       "GVS_406_W_T2                 44                 44                 44   \n",
       "GVS_407_W_T2                 39                 39                 39   \n",
       "GVS_408_W_T2                 44                 44                 44   \n",
       "GVS_409_W_T2                 44                 44                 44   \n",
       "GVS_410_W_T1                 41                 41                 41   \n",
       "GVS_411_W_T1                 39                 39                 39   \n",
       "GVS_411_W_T3                 39                 39                 39   \n",
       "\n",
       "              toe 2-x-asymmetry  toe 2-y-asymmetry  toe 2-z-asymmetry  \n",
       "video                                                                  \n",
       "GVS_102_W_T1                 90                 90                 90  \n",
       "GVS_112_W_T1                 95                 95                 95  \n",
       "GVS_113_W_T1                 57                 57                 57  \n",
       "GVS_115_W_T1                 52                 52                 52  \n",
       "GVS_123_W_T1                118                118                118  \n",
       "GVS_124_W_T1                 63                 63                 63  \n",
       "GVS_212_W_T2                 44                 44                 44  \n",
       "GVS_213_W_T1                 43                 43                 43  \n",
       "GVS_214_W_T1                 38                 38                 38  \n",
       "GVS_215_W_T1                 45                 45                 45  \n",
       "GVS_216_W_T2                 40                 40                 40  \n",
       "GVS_217_W_T1                 39                 39                 39  \n",
       "GVS_218_W_T2                 45                 45                 45  \n",
       "GVS_219_W_T2                 40                 40                 40  \n",
       "GVS_310_W_T1                 41                 41                 41  \n",
       "GVS_311_W_T1                 43                 43                 43  \n",
       "GVS_312_W_T2                 48                 48                 48  \n",
       "GVS_313_W_T1                 38                 38                 38  \n",
       "GVS_314_W_T1                 38                 38                 38  \n",
       "GVS_318_W_T1                 17                 17                 17  \n",
       "GVS_320_W_T1                 45                 45                 45  \n",
       "GVS_321_W_T1                 39                 39                 39  \n",
       "GVS_322_W_T2                 40                 40                 40  \n",
       "GVS_323_W_T1                 40                 40                 40  \n",
       "GVS_404_W_T2                 41                 41                 41  \n",
       "GVS_404_W_T3                 41                 41                 41  \n",
       "GVS_405_W_T1                 41                 41                 41  \n",
       "GVS_405_W_T3                 40                 40                 40  \n",
       "GVS_406_W_T2                 44                 44                 44  \n",
       "GVS_407_W_T2                 39                 39                 39  \n",
       "GVS_408_W_T2                 44                 44                 44  \n",
       "GVS_409_W_T2                 44                 44                 44  \n",
       "GVS_410_W_T1                 41                 41                 41  \n",
       "GVS_411_W_T1                 39                 39                 39  \n",
       "GVS_411_W_T3                 39                 39                 39  \n",
       "\n",
       "[35 rows x 98 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trialW.groupby(['video']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['logistic_regression', 'random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  \\\n",
    "             'linear_svm', 'mlp']\n",
    "metrics = pd.DataFrame(columns = ml_models) #Dataframe to store accuracies for each ML model for raw data \n",
    "\n",
    "#For storing predicted probabilities for person (for all classes HOA/MS/PD) to show ROC curves \n",
    "predicted_probs_person = pd.DataFrame(columns = [ml_model + cohort for ml_model in ml_models for cohort in ['_HOA', '_MS', '_PD'] ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachneet Kaur\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stride-based model performance:  0.7898423817863398 0.7851457094388344 0.7810243824300049 0.780240606863425 0.9194723515404934\n",
      "Person-based model performance:  0.92 0.9333333333333332 0.9259259259259259 0.9212962962962964 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************\n",
      "random_forest\n"
     ]
    }
   ],
   "source": [
    "for ml_model in ml_models:\n",
    "    print (ml_model)\n",
    "    predict_probs_person, stride_person_metrics = models(trainX_norm, trainY, testX_norm, testY, ml_model, framework)  \n",
    "    metrics[ml_model] = stride_person_metrics\n",
    "    predicted_probs_person[ml_model+'_HOA'] = predict_probs_person[0]\n",
    "    predicted_probs_person[ml_model+'_MS'] = predict_probs_person[1]\n",
    "    predicted_probs_person[ml_model+'_PD'] = predict_probs_person[2]\n",
    "    print ('********************************')\n",
    "\n",
    "metrics.index = ['stride_accuracy', 'stride_precision', 'stride_recall', 'stride_F1', 'stride_AUC', 'person_accuracy', \n",
    "                     'person_precision', 'person_recall', 'person_F1', 'person_AUC']  \n",
    "metrics.to_csv(results_path+ framework+ '\\\\task_generalize_'+framework+'_result_metrics.csv')\n",
    "predicted_probs_person.to_csv(results_path +framework+ '\\\\task_generalize_'+framework+'_prediction_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ROC(ml_models, testY, predicted_probs_person, framework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Task generalization framework 2: train on virtual beam walking (VBW) and test on virtual beam walking while talking (VBWT) with traditional ML algorithms to classify strides and subjects in HOA/MS/PD groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial VBW for training \n",
    "trialVBW = data[data['scenario']=='SLW']\n",
    "#Trial VBWT for testing \n",
    "trialVBWT = data[data['scenario']=='SLWT']\n",
    "\n",
    "#Trial VBW and VBWT after making sure both training and testing sets have common subjects \n",
    "trialVBW_reduced, trialVBWT_reduced = keep_subjects_common_across_train_test(trialVBW, trialVBWT)\n",
    "# print ('Number of subjects in training and test sets after reduction:', len(trialW_reduced['PID'].unique()), \\\n",
    "#            len(trialWT_reduced['PID'].unique()))\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the training stride data\n",
    "trialVBW_reduced = shuffle(trialVBW_reduced, random_state = 0)\n",
    "trainX_VBW = trialVBW_reduced.drop(cols_to_drop, axis = 1)\n",
    "trainY_VBW = trialVBW_reduced[['PID', 'label']]\n",
    "print ('Training shape', trainX_VBW.shape, trainY_VBW.shape)\n",
    "\n",
    "#Shuffling the testing stride data \n",
    "trialVBWT_reduced = shuffle(trialVBWT_reduced, random_state = 0)\n",
    "testX_VBWT = trialVBWT_reduced.drop(cols_to_drop, axis = 1)\n",
    "testY_VBWT = trialVBWT_reduced[['PID', 'label']] #PID to compute person based metrics later \n",
    "print ('Testing shape', testX_VBWT.shape, testY_VBWT.shape)\n",
    "\n",
    "#Normalize according to z-score standardization\n",
    "norm_mean_VB, norm_sd_VB = normalize(trainX_VBW, 'z')\n",
    "trainX_norm_VBW = (trainX_VBW-norm_mean_VB)/norm_sd_VB\n",
    "testX_norm_VBWT = (testX_VBWT-norm_mean_VB)/norm_sd_VB\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in training set: ', len(trialVBW_reduced))\n",
    "print ('HOA, MS and PD strides in training set:\\n', trialVBW_reduced['cohort'].value_counts())\n",
    "\n",
    "#Test Set\n",
    "print('\\nStrides in test set: ', len(trialVBWT_reduced)) \n",
    "print ('HOA, MS and PD strides in test set:\\n', trialVBWT_reduced['cohort'].value_counts())\n",
    "print ('Imbalance ratio (controls:MS:PD)= 1:X:Y\\n', trialVBWT_reduced['cohort'].value_counts()/trialVBWT_reduced['cohort'].value_counts()['HOA'])\n",
    "\n",
    "framework = 'VBWtoVBWT' #Defining the task generalization framework of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_VB = pd.DataFrame(columns = ml_models) #Dataframe to store accuracies for each ML model for raw data \n",
    "#For storing predicted probabilities for person (for classes HOA/MS/PD) to show ROC curves \n",
    "predicted_probs_person_VB = pd.DataFrame(columns = [ml_model + cohort for ml_model in ml_models for cohort in ['_HOA', '_MS', '_PD'] ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ml_model in ml_models:\n",
    "    print (ml_model)\n",
    "    predict_probs_person_VB, stride_person_metrics_VB = models(trainX_norm_VBW, trainY_VBW, testX_norm_VBWT, testY_VBWT, ml_model, \\\n",
    "                                                              framework)\n",
    "    metrics_VB[ml_model] = stride_person_metrics_VB\n",
    "    predicted_probs_person_VB[ml_model+'_HOA'] = predict_probs_person_VB[0]\n",
    "    predicted_probs_person_VB[ml_model+'_MS'] = predict_probs_person_VB[1]\n",
    "    predicted_probs_person_VB[ml_model+'_PD'] = predict_probs_person_VB[2]\n",
    "    print ('********************************')\n",
    "\n",
    "metrics_VB.index = ['stride_accuracy', 'stride_precision', 'stride_recall', 'stride_F1', 'stride_AUC', 'person_accuracy', \n",
    "                     'person_precision', 'person_recall', 'person_F1', 'person_AUC']  \n",
    "metrics_VB.to_csv(results_path+ framework+ '\\\\task_generalize_'+framework+'_result_metrics.csv')\n",
    "predicted_probs_person_VB.to_csv(results_path+framework+'\\\\task_generalize_'+framework+'_prediction_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_VB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ROC \n",
    "plot_ROC(ml_models, testY_VBWT, predicted_probs_person_VB, framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrices - Done\n",
    "#micro/macro/weighted metric scores \n",
    "#Why is AUC 1 for low accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
