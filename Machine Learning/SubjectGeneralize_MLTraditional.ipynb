{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gait Video Study \n",
    "### Traditional ML algorithms on subject generalization frameworks, namely a) W, b) WT, c) VBW and d) VBWT,  to classify HOA/MS/PD strides and subjects using cross validation \n",
    "#### Remember to add the original count of frames in a single stride (before down sampling via smoothing) for each stride as an additional artificial feature to add information about speed of the subject to the model\n",
    "1. Save the optimal hyperparameters, confusion matrices and ROC curves for each algorithm.\n",
    "2. Make sure to not use x, y, z, confidence = 0, 0, 0, 0 as points for the model since they are simply missing values and not data points, so make sure to treat them before inputting to model \n",
    "3. Make sure to normalize (z-score normalization) the features before we feed them to the model.\n",
    "4. We use the summary statistics as range, CoV and asymmetry between the right and left limbs as the features to input to the traditional models requiring fixed size 1D input for each training/testing set sample.\n",
    "5. We use Group 5-fold stratified cross validation for evaluation.\n",
    "6. Compare traditional algorithms among the 4 sub-frameworks of subject generalization by retaining only common subjets across the 4 frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from ml_utils.imports import *\n",
    "\n",
    "from ml_utils import subject_gen_traditionalML\n",
    "reload(subject_gen_traditionalML)\n",
    "from ml_utils.subject_gen_traditionalML import keep_common_PIDs, models, evaluate, run_ml_models\n",
    "from ml_utils.subject_gen_traditionalML import design, plot_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>cohort</th>\n",
       "      <th>trial</th>\n",
       "      <th>scenario</th>\n",
       "      <th>video</th>\n",
       "      <th>PID</th>\n",
       "      <th>stride_number</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>label</th>\n",
       "      <th>right hip-x-CoV</th>\n",
       "      <th>...</th>\n",
       "      <th>ankle-z-asymmetry</th>\n",
       "      <th>heel-x-asymmetry</th>\n",
       "      <th>heel-y-asymmetry</th>\n",
       "      <th>heel-z-asymmetry</th>\n",
       "      <th>toe 1-x-asymmetry</th>\n",
       "      <th>toe 1-y-asymmetry</th>\n",
       "      <th>toe 1-z-asymmetry</th>\n",
       "      <th>toe 2-x-asymmetry</th>\n",
       "      <th>toe 2-y-asymmetry</th>\n",
       "      <th>toe 2-z-asymmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GVS_212_T_T1_1</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046077</td>\n",
       "      <td>...</td>\n",
       "      <td>14.426173</td>\n",
       "      <td>3.407379</td>\n",
       "      <td>10.662441</td>\n",
       "      <td>0.830365</td>\n",
       "      <td>0.502570</td>\n",
       "      <td>31.450487</td>\n",
       "      <td>8.644012</td>\n",
       "      <td>5.236678</td>\n",
       "      <td>31.182183</td>\n",
       "      <td>8.215725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GVS_212_T_T1_2</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.360847</td>\n",
       "      <td>5.155307</td>\n",
       "      <td>11.363806</td>\n",
       "      <td>4.333776</td>\n",
       "      <td>1.025647</td>\n",
       "      <td>28.266400</td>\n",
       "      <td>2.671081</td>\n",
       "      <td>6.678294</td>\n",
       "      <td>15.058825</td>\n",
       "      <td>4.903579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GVS_212_T_T1_3</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034394</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341021</td>\n",
       "      <td>8.625363</td>\n",
       "      <td>7.159495</td>\n",
       "      <td>3.366152</td>\n",
       "      <td>1.759968</td>\n",
       "      <td>17.545787</td>\n",
       "      <td>5.921325</td>\n",
       "      <td>8.243491</td>\n",
       "      <td>9.578638</td>\n",
       "      <td>3.008162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GVS_212_T_T1_4</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028511</td>\n",
       "      <td>...</td>\n",
       "      <td>2.375934</td>\n",
       "      <td>6.728268</td>\n",
       "      <td>0.098235</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>0.541911</td>\n",
       "      <td>7.843339</td>\n",
       "      <td>4.279617</td>\n",
       "      <td>0.748023</td>\n",
       "      <td>19.471731</td>\n",
       "      <td>5.086056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GVS_212_T_T1_5</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>...</td>\n",
       "      <td>8.525816</td>\n",
       "      <td>1.775282</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>9.166863</td>\n",
       "      <td>1.354601</td>\n",
       "      <td>6.674183</td>\n",
       "      <td>8.479480</td>\n",
       "      <td>4.373622</td>\n",
       "      <td>0.315168</td>\n",
       "      <td>11.795593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              key cohort trial scenario         video  PID  stride_number  \\\n",
       "0  GVS_212_T_T1_1    HOA    BW     SLWT  GVS_212_T_T1  212              1   \n",
       "1  GVS_212_T_T1_2    HOA    BW     SLWT  GVS_212_T_T1  212              2   \n",
       "2  GVS_212_T_T1_3    HOA    BW     SLWT  GVS_212_T_T1  212              3   \n",
       "3  GVS_212_T_T1_4    HOA    BW     SLWT  GVS_212_T_T1  212              4   \n",
       "4  GVS_212_T_T1_5    HOA    BW     SLWT  GVS_212_T_T1  212              5   \n",
       "\n",
       "   frame_count  label  right hip-x-CoV  ...  ankle-z-asymmetry  \\\n",
       "0           46      0         0.046077  ...          14.426173   \n",
       "1           39      0         0.021528  ...           1.360847   \n",
       "2           56      0         0.034394  ...           1.341021   \n",
       "3           53      0         0.028511  ...           2.375934   \n",
       "4           44      0         0.025213  ...           8.525816   \n",
       "\n",
       "   heel-x-asymmetry  heel-y-asymmetry  heel-z-asymmetry  toe 1-x-asymmetry  \\\n",
       "0          3.407379         10.662441          0.830365           0.502570   \n",
       "1          5.155307         11.363806          4.333776           1.025647   \n",
       "2          8.625363          7.159495          3.366152           1.759968   \n",
       "3          6.728268          0.098235          0.999027           0.541911   \n",
       "4          1.775282          0.033210          9.166863           1.354601   \n",
       "\n",
       "   toe 1-y-asymmetry  toe 1-z-asymmetry  toe 2-x-asymmetry  toe 2-y-asymmetry  \\\n",
       "0          31.450487           8.644012           5.236678          31.182183   \n",
       "1          28.266400           2.671081           6.678294          15.058825   \n",
       "2          17.545787           5.921325           8.243491           9.578638   \n",
       "3           7.843339           4.279617           0.748023          19.471731   \n",
       "4           6.674183           8.479480           4.373622           0.315168   \n",
       "\n",
       "   toe 2-z-asymmetry  \n",
       "0           8.215725  \n",
       "1           4.903579  \n",
       "2           3.008162  \n",
       "3           5.086056  \n",
       "4          11.795593  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\Rachneet Kaur\\\\Box\\\\Gait Video Project\\\\GaitVideoData\\\\video\\\\'\n",
    "data_path = path+'traditional_methods_dataframe.csv'\n",
    "results_path = 'C:\\\\Users\\\\Rachneet Kaur\\\\Box\\Gait Video Project\\\\MLresults\\\\'\n",
    "\n",
    "data = pd.read_csv(data_path, index_col= 0)\n",
    "display(data.head())\n",
    "\n",
    "#Whether to save the results (confusion matrices and RoC plots) or not \n",
    "save_results = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject generalization framework 1: walking (W) to classify HOA/MS/PD strides and subjects using cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of subjects in trial W for cross validation: 32\n",
      "Number of subjects in trial W in each cohort:\n",
      " HOA    14\n",
      "MS     10\n",
      "PD      8\n",
      "Name: cohort, dtype: int64\n",
      "Strides in trial W for cross validation:  1380\n",
      "HOA, MS and PD strides in trial W:\n",
      " HOA    658\n",
      "MS     389\n",
      "PD     333\n",
      "Name: cohort, dtype: int64\n",
      "Imbalance ratio in trial W (controls:MS:PD)= 1:X:Y\n",
      " HOA    1.000000\n",
      "MS     0.591185\n",
      "PD     0.506079\n",
      "Name: cohort, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Trial W for the first framework of subject generalization\n",
    "trialW = data[data['scenario']=='W']\n",
    "print ('Original number of subjects in trial W for cross validation:', len(trialW['PID'].unique()))\n",
    "print ('Number of subjects in trial W in each cohort:\\n', trialW.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialW = shuffle(trialW, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X = trialW.drop(cols_to_drop, axis = 1)\n",
    "Y = trialW[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial W for cross validation: ', len(trialW))\n",
    "print ('HOA, MS and PD strides in trial W:\\n', trialW['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial W (controls:MS:PD)= 1:X:Y\\n', trialW['cohort'].value_counts()/trialW['cohort'].value_counts()['HOA'])\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n"
     ]
    }
   ],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "# ml_models = ['logistic_regression']\n",
    "metrics = run_ml_models(ml_models, X, Y, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject generalization framework 2: walking while talking (WT) to classify strides and subjects of HOA/MS/PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial WT for the second framework of subject generalization\n",
    "trialWT = data[data['scenario']=='WT']\n",
    "print ('Original number of subjects in trial WT for cross validation:', len(trialWT['PID'].unique()))\n",
    "print ('Number of subjects in trial WT in each cohort:\\n', trialWT.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialWT = shuffle(trialWT, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_WT = trialWT.drop(cols_to_drop, axis = 1)\n",
    "Y_WT = trialWT[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial WT for cross validation: ', len(trialWT))\n",
    "print ('HOA, MS and PD strides in trial WT:\\n', trialWT['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial WT (controls:MS:PD)= 1:X:Y\\n', trialWT['cohort'].value_counts()/trialWT['cohort'].value_counts()['HOA'])\n",
    "#Defining the framework of interest\n",
    "framework = 'WT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_WT = run_ml_models(ml_models, X_WT, Y_WT, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_WT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject generalization framework 3: virtual beam walking (VBW) to classify strides and subjects of HOA/MS/PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial VBW for the third framework of subject generalization\n",
    "trialVBW = data[data['scenario']=='SLW']\n",
    "print ('Original number of subjects in trial VBW for cross validation:', len(trialVBW['PID'].unique()))\n",
    "print ('Number of subjects in trial VBW in each cohort:\\n', trialVBW.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialVBW = shuffle(trialVBW, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_VBW = trialVBW.drop(cols_to_drop, axis = 1)\n",
    "Y_VBW = trialVBW[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial VBW for cross validation: ', len(trialVBW))\n",
    "print ('HOA, MS and PD strides in trial VBW:\\n', trialVBW['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial VBW (controls:MS:PD)= 1:X:Y\\n', trialVBW['cohort'].value_counts()/trialVBW['cohort'].value_counts()['HOA'])\n",
    "#Defining the framework of interest\n",
    "framework = 'VBW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_VBW = run_ml_models(ml_models, X_VBW, Y_VBW, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_VBW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject generalization framework 4: virtual beam walking while talking (VBWT) to classify strides and subjects of HOA/MS/PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial VBWT for the fourth framework of subject generalization\n",
    "trialVBWT = data[data['scenario']=='SLWT']\n",
    "print ('Original number of subjects in trial VBWT for cross validation:', len(trialVBWT['PID'].unique()))\n",
    "print ('Number of subjects in trial VBWT in each cohort:\\n', trialVBWT.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialVBWT = shuffle(trialVBWT, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_VBWT = trialVBWT.drop(cols_to_drop, axis = 1)\n",
    "Y_VBWT = trialVBWT[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial VBWT for cross validation: ', len(trialVBWT))\n",
    "print ('HOA, MS and PD strides in trial VBWT:\\n', trialVBWT['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial VBWT (controls:MS:PD)= 1:X:Y\\n', trialVBWT['cohort'].value_counts()/trialVBWT['cohort'].value_counts()['HOA'])\n",
    "#Defining the framework of interest\n",
    "framework = 'VBWT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_VBWT = run_ml_models(ml_models, X_VBWT, Y_VBWT, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_VBWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do!\n",
    "#ROC- Done \n",
    "#Confusion matrix files - Done\n",
    "#CF itself - Done\n",
    "#Saving all results to results folder - Done\n",
    "#Comments in utility functions - Done\n",
    "#micro macro weighted save all results \n",
    "#How can we compare different frameworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare traditional algorithms among the 4 sub-frameworks of subject generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To compare across the 4 sub-frameworks of subject generalization, we reduce to common subjects across all 4 sub-frameworks \n",
    "#and then compare for the best accuracy/model in each sub-framework \n",
    "\n",
    "#Retaining the common PIDs across the 4 tasks \n",
    "common_pids = keep_common_PIDs(data, ['W', 'WT', 'SLW', 'SLWT'])\n",
    "\n",
    "#Retaining the data with only common PIDs\n",
    "reduced_data = data[data.PID.isin(common_pids)]\n",
    "print ('Number of subjects in each cohort in reduced data with common PIDs:\\n', \\\n",
    "       reduced_data.groupby('PID').first()['cohort'].value_counts())\n",
    "design()\n",
    "#Checking the retained strides in each task after reducing to commpn PIDs only\n",
    "for scen in ['W', 'WT', 'SLW', 'SLWT']:\n",
    "    reduced_data_scen = reduced_data[reduced_data.scenario==scen].reset_index().drop('index', axis = 1)\n",
    "    print ('No. of strides retained in scenario', scen, 'are: ', reduced_data_scen.shape)\n",
    "    print ('No. of strides retained for each cohort in scenario', scen, 'are:\\n', reduced_data_scen['cohort'].value_counts())\n",
    "    print ('Imbalance ratio in scenario', scen, '(controls:MS:PD)= 1:X:Y\\n', \\\n",
    "           reduced_data_scen['cohort'].value_counts()/reduced_data_scen['cohort'].value_counts()['HOA'])\n",
    "    design()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the traditional models again for all sub-frameworks of suject generalization to give a ranking of best to worst \n",
    "#tasks for subject generalization \n",
    "\n",
    "#Trial W\n",
    "reduced_data_W = reduced_data[reduced_data.scenario=='W'].reset_index().drop('index', axis = 1)\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "\n",
    "#Shuffling the cross validation stride data\n",
    "reduced_data_W = shuffle(reduced_data_W, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_reduced_data_W = reduced_data_W.drop(cols_to_drop, axis = 1)\n",
    "Y_reduced_data_W = reduced_data_W[['PID', 'label']]\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'reducedW_for_comparision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_reducedW_for_comparision = run_ml_models(ml_models, X_reduced_data_W, Y_reduced_data_W, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reducedW_for_comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the traditional models again for all sub-frameworks of suject generalization to give a ranking of best to worst \n",
    "#tasks for subject generalization \n",
    "\n",
    "#Trial WT\n",
    "reduced_data_WT = reduced_data[reduced_data.scenario=='WT'].reset_index().drop('index', axis = 1)\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "\n",
    "#Shuffling the cross validation stride data\n",
    "reduced_data_WT = shuffle(reduced_data_WT, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_reduced_data_WT = reduced_data_WT.drop(cols_to_drop, axis = 1)\n",
    "Y_reduced_data_WT = reduced_data_WT[['PID', 'label']]\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'reducedWT_for_comparision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_reducedWT_for_comparision = run_ml_models(ml_models, X_reduced_data_WT, Y_reduced_data_WT, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reducedWT_for_comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial VBW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the traditional models again for all sub-frameworks of suject generalization to give a ranking of best to worst \n",
    "#tasks for subject generalization \n",
    "\n",
    "#Trial VBW\n",
    "reduced_data_VBW = reduced_data[reduced_data.scenario=='SLW'].reset_index().drop('index', axis = 1)\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "\n",
    "#Shuffling the cross validation stride data\n",
    "reduced_data_VBW = shuffle(reduced_data_VBW, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_reduced_data_VBW = reduced_data_VBW.drop(cols_to_drop, axis = 1)\n",
    "Y_reduced_data_VBW = reduced_data_VBW[['PID', 'label']]\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'reducedVBW_for_comparision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_reducedVBW_for_comparision = run_ml_models(ml_models, X_reduced_data_VBW, Y_reduced_data_VBW, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reducedVBW_for_comparision\n",
    "#HOA is doing better than W and WT even though not in full model \n",
    "#Sequential test - this is screening test - first classify HOA or not using VBW task and then then do further screening out of PD/MS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial VBWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the traditional models again for all sub-frameworks of suject generalization to give a ranking of best to worst \n",
    "#tasks for subject generalization \n",
    "\n",
    "#Trial VBWT\n",
    "reduced_data_VBWT = reduced_data[reduced_data.scenario=='SLWT'].reset_index().drop('index', axis = 1)\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "\n",
    "#Shuffling the cross validation stride data\n",
    "reduced_data_VBWT = shuffle(reduced_data_VBWT, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_reduced_data_VBWT = reduced_data_VBWT.drop(cols_to_drop, axis = 1)\n",
    "Y_reduced_data_VBWT = reduced_data_VBWT[['PID', 'label']]\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'reducedVBWT_for_comparision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_reducedVBWT_for_comparision = run_ml_models(ml_models, X_reduced_data_VBWT, Y_reduced_data_VBWT, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reducedVBWT_for_comparision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS of comparing 4 sub-frameworks for subject generalization\n",
    "#WT>>W>>VBWT>>VBW \n",
    "#VBW is screening test since it performs well (looking at the confusion matrix) for predicting HOA or not, but we need something more to \n",
    "#distinguish well between the two neurological populations (MS and PD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare traditional algorithms among the 2 sub-frameworks of subject generalization, namely W and WT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To compare across the 2 sub-frameworks of subject generalization, we reduce to common subjects across all 2 sub-frameworks \n",
    "#and then compare for the best accuracy/model in each sub-framework \n",
    "\n",
    "#Retaining the common PIDs across the 2 walking tasks \n",
    "common_pids = keep_common_PIDs(data, ['W', 'WT'])\n",
    "\n",
    "#Retaining the data with only common PIDs\n",
    "reduced_data = data[data.PID.isin(common_pids)]\n",
    "print ('Number of subjects in each cohort in reduced data with common PIDs:\\n', \\\n",
    "       reduced_data.groupby('PID').first()['cohort'].value_counts())\n",
    "design()\n",
    "#Checking the retained strides in each task after reducing to commpn PIDs only\n",
    "for scen in ['W', 'WT']:\n",
    "    reduced_data_scen = reduced_data[reduced_data.scenario==scen].reset_index().drop('index', axis = 1)\n",
    "    print ('No. of strides retained in scenario', scen, 'are: ', reduced_data_scen.shape)\n",
    "    print ('No. of strides retained for each cohort in scenario', scen, 'are:\\n', reduced_data_scen['cohort'].value_counts())\n",
    "    print ('Imbalance ratio in scenario', scen, '(controls:MS:PD)= 1:X:Y\\n', \\\n",
    "           reduced_data_scen['cohort'].value_counts()/reduced_data_scen['cohort'].value_counts()['HOA'])\n",
    "    design()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the traditional models again for all sub-frameworks of suject generalization to give a ranking of best to worst \n",
    "#tasks for subject generalization \n",
    "\n",
    "#Trial W\n",
    "reduced_data_W = reduced_data[reduced_data.scenario=='W'].reset_index().drop('index', axis = 1)\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "\n",
    "#Shuffling the cross validation stride data\n",
    "reduced_data_W = shuffle(reduced_data_W, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_reduced_data_W = reduced_data_W.drop(cols_to_drop, axis = 1)\n",
    "Y_reduced_data_W = reduced_data_W[['PID', 'label']]\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'reducedW_for_comparision_WandWTonly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_reducedW_for_comparision_WandWTonly = run_ml_models(ml_models, X_reduced_data_W, Y_reduced_data_W, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reducedW_for_comparision_WandWTonly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the traditional models again for all sub-frameworks of suject generalization to give a ranking of best to worst \n",
    "#tasks for subject generalization \n",
    "\n",
    "#Trial WT\n",
    "reduced_data_WT = reduced_data[reduced_data.scenario=='WT'].reset_index().drop('index', axis = 1)\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "\n",
    "#Shuffling the cross validation stride data\n",
    "reduced_data_WT = shuffle(reduced_data_WT, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_reduced_data_WT = reduced_data_WT.drop(cols_to_drop, axis = 1)\n",
    "Y_reduced_data_WT = reduced_data_WT[['PID', 'label']]\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'reducedWT_for_comparision_WandWTonly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_reducedWT_for_comparision_WandWTonly = run_ml_models(ml_models, X_reduced_data_WT, Y_reduced_data_WT, framework, results_path, save_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reducedWT_for_comparision_WandWTonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
