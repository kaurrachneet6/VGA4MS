{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gait Video Study \n",
    "### Traditional ML algorithms on subject generalization framework 1: walking (W) to classify HOA/MS/PD strides and subjects using cross validation \n",
    "#### Remember to add the original count of frames in a single stride (before down sampling via smoothing) for each stride as an additional artificial feature to add information about speed of the subject to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import imports \n",
    "reload(imports)\n",
    "from imports import *\n",
    "from split import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>cohort</th>\n",
       "      <th>trial</th>\n",
       "      <th>scenario</th>\n",
       "      <th>video</th>\n",
       "      <th>PID</th>\n",
       "      <th>stride_number</th>\n",
       "      <th>frame_count</th>\n",
       "      <th>label</th>\n",
       "      <th>right hip-x-CoV</th>\n",
       "      <th>...</th>\n",
       "      <th>ankle-z-asymmetry</th>\n",
       "      <th>heel-x-asymmetry</th>\n",
       "      <th>heel-y-asymmetry</th>\n",
       "      <th>heel-z-asymmetry</th>\n",
       "      <th>toe 1-x-asymmetry</th>\n",
       "      <th>toe 1-y-asymmetry</th>\n",
       "      <th>toe 1-z-asymmetry</th>\n",
       "      <th>toe 2-x-asymmetry</th>\n",
       "      <th>toe 2-y-asymmetry</th>\n",
       "      <th>toe 2-z-asymmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GVS_212_T_T1_1</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046077</td>\n",
       "      <td>...</td>\n",
       "      <td>14.426173</td>\n",
       "      <td>3.407379</td>\n",
       "      <td>10.662441</td>\n",
       "      <td>0.830365</td>\n",
       "      <td>0.502570</td>\n",
       "      <td>31.450487</td>\n",
       "      <td>8.644012</td>\n",
       "      <td>5.236678</td>\n",
       "      <td>31.182183</td>\n",
       "      <td>8.215725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GVS_212_T_T1_2</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.360847</td>\n",
       "      <td>5.155307</td>\n",
       "      <td>11.363806</td>\n",
       "      <td>4.333776</td>\n",
       "      <td>1.025647</td>\n",
       "      <td>28.266400</td>\n",
       "      <td>2.671081</td>\n",
       "      <td>6.678294</td>\n",
       "      <td>15.058825</td>\n",
       "      <td>4.903579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GVS_212_T_T1_3</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034394</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341021</td>\n",
       "      <td>8.625363</td>\n",
       "      <td>7.159495</td>\n",
       "      <td>3.366152</td>\n",
       "      <td>1.759968</td>\n",
       "      <td>17.545787</td>\n",
       "      <td>5.921325</td>\n",
       "      <td>8.243491</td>\n",
       "      <td>9.578638</td>\n",
       "      <td>3.008162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GVS_212_T_T1_4</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028511</td>\n",
       "      <td>...</td>\n",
       "      <td>2.375934</td>\n",
       "      <td>6.728268</td>\n",
       "      <td>0.098235</td>\n",
       "      <td>0.999027</td>\n",
       "      <td>0.541911</td>\n",
       "      <td>7.843339</td>\n",
       "      <td>4.279617</td>\n",
       "      <td>0.748023</td>\n",
       "      <td>19.471731</td>\n",
       "      <td>5.086056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GVS_212_T_T1_5</td>\n",
       "      <td>HOA</td>\n",
       "      <td>BW</td>\n",
       "      <td>SLWT</td>\n",
       "      <td>GVS_212_T_T1</td>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025213</td>\n",
       "      <td>...</td>\n",
       "      <td>8.525816</td>\n",
       "      <td>1.775282</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>9.166863</td>\n",
       "      <td>1.354601</td>\n",
       "      <td>6.674183</td>\n",
       "      <td>8.479480</td>\n",
       "      <td>4.373622</td>\n",
       "      <td>0.315168</td>\n",
       "      <td>11.795593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              key cohort trial scenario         video  PID  stride_number  \\\n",
       "0  GVS_212_T_T1_1    HOA    BW     SLWT  GVS_212_T_T1  212              1   \n",
       "1  GVS_212_T_T1_2    HOA    BW     SLWT  GVS_212_T_T1  212              2   \n",
       "2  GVS_212_T_T1_3    HOA    BW     SLWT  GVS_212_T_T1  212              3   \n",
       "3  GVS_212_T_T1_4    HOA    BW     SLWT  GVS_212_T_T1  212              4   \n",
       "4  GVS_212_T_T1_5    HOA    BW     SLWT  GVS_212_T_T1  212              5   \n",
       "\n",
       "   frame_count  label  right hip-x-CoV  ...  ankle-z-asymmetry  \\\n",
       "0           46      0         0.046077  ...          14.426173   \n",
       "1           39      0         0.021528  ...           1.360847   \n",
       "2           56      0         0.034394  ...           1.341021   \n",
       "3           53      0         0.028511  ...           2.375934   \n",
       "4           44      0         0.025213  ...           8.525816   \n",
       "\n",
       "   heel-x-asymmetry  heel-y-asymmetry  heel-z-asymmetry  toe 1-x-asymmetry  \\\n",
       "0          3.407379         10.662441          0.830365           0.502570   \n",
       "1          5.155307         11.363806          4.333776           1.025647   \n",
       "2          8.625363          7.159495          3.366152           1.759968   \n",
       "3          6.728268          0.098235          0.999027           0.541911   \n",
       "4          1.775282          0.033210          9.166863           1.354601   \n",
       "\n",
       "   toe 1-y-asymmetry  toe 1-z-asymmetry  toe 2-x-asymmetry  toe 2-y-asymmetry  \\\n",
       "0          31.450487           8.644012           5.236678          31.182183   \n",
       "1          28.266400           2.671081           6.678294          15.058825   \n",
       "2          17.545787           5.921325           8.243491           9.578638   \n",
       "3           7.843339           4.279617           0.748023          19.471731   \n",
       "4           6.674183           8.479480           4.373622           0.315168   \n",
       "\n",
       "   toe 2-z-asymmetry  \n",
       "0           8.215725  \n",
       "1           4.903579  \n",
       "2           3.008162  \n",
       "3           5.086056  \n",
       "4          11.795593  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\Rachneet Kaur\\\\Box\\\\Gait Video Project\\\\GaitVideoData\\\\video\\\\'\n",
    "data_path = path+'traditional_methods_dataframe.csv'\n",
    "results_path = 'C:\\\\Users\\\\Rachneet Kaur\\\\Box\\Gait Video Project\\\\MLresults\\\\'\n",
    "\n",
    "data = pd.read_csv(data_path, index_col= 0)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, yoriginal_, ypredicted_, framework, model_name):\n",
    "    '''\n",
    "    Arguments: trained model, test set, true and predicted labels for test set, framework and model name \n",
    "    Returns: predicted probabilities and labels for each class, stride and subject based evaluation metrics \n",
    "    Saves the csv files for stride wise predictions and subject wise predictions for confusion matrix \n",
    "    '''\n",
    "    #For creating the stride wise confusion matrix, we append the true and predicted labels for strides in each fold to this \n",
    "    #test_strides_true_predicted_labels dataframe \n",
    "    test_strides_true_predicted_labels = pd.DataFrame()\n",
    "    #For creating the subject wise confusion matrix, we append the true and predicted labels for subjects in each fold to this\n",
    "    #test_subjects_true_predicted_labels dataframe\n",
    "    test_subjects_true_predicted_labels = pd.DataFrame()\n",
    "    \n",
    "    best_index = model.cv_results_['mean_test_accuracy'].argmax()\n",
    "    print('best_params: ', model.cv_results_['params'][best_index])\n",
    "\n",
    "    #Stride-wise metrics \n",
    "    stride_metrics_mean, stride_metrics_std = [], [] #Mean and SD of stride based metrics - Acc, P, R, F1, AUC (in order)\n",
    "    scores={'accuracy': make_scorer(acc), 'precision':make_scorer(precision_score, average = 'macro'), \\\n",
    "            'recall':make_scorer(recall_score, average = 'macro'), 'f1': make_scorer(f1_score, average = 'macro'), \\\n",
    "           'auc': make_scorer(roc_auc_score, average = 'macro', multi_class = 'ovo', needs_proba= True)}\n",
    "    \n",
    "    for score in scores:\n",
    "        stride_metrics_mean.append(model.cv_results_['mean_test_'+score][best_index])\n",
    "        stride_metrics_std.append(model.cv_results_['std_test_'+score][best_index])\n",
    "    print('Stride-based model performance (mean): ', stride_metrics_mean)\n",
    "    print('Stride-based model performance (standard deviation): ', stride_metrics_std)\n",
    "    n_folds = 5\n",
    "    person_acc, person_p, person_r, person_f1, person_auc = [], [], [], [], []\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        #For each fold, there are 2 splits: test and train (in order) and we need to retrieve the index \n",
    "        #of only test set for required 5 folds (best index)\n",
    "        temp = test_features.loc[yoriginal_[(best_index*n_folds) + (i)].index] #True labels for the test strides in each fold\n",
    "        temp['pred'] = ypredicted_[(best_index*n_folds) + (i)] #Predicted labels for the strides in the test set in each fold\n",
    "#         print ('temp_pred', temp['pred'])\n",
    "        #Appending the test strides' true and predicted label for each fold to compute stride-wise confusion matrix \n",
    "        test_strides_true_predicted_labels = test_strides_true_predicted_labels.append(temp)\n",
    "        \n",
    "        x = temp.groupby('PID')['pred'].value_counts().unstack()\n",
    "#         print ('x', x)\n",
    "        #Input for subject wise AUC is probabilities at columns [0, 1, 2]\n",
    "        proportion_strides_correct = pd.DataFrame(columns = [0, 1, 2])\n",
    "        probs_stride_wise = x.divide(x.sum(axis = 1), axis = 0).fillna(0)\n",
    "        proportion_strides_correct[probs_stride_wise.columns] = probs_stride_wise\n",
    "        proportion_strides_correct.fillna(0, inplace=True)\n",
    "        proportion_strides_correct['True Label'] = test_features.groupby('PID').first()\n",
    "        #Input for precision, recall and F1 score\n",
    "        proportion_strides_correct['Predicted Label'] = proportion_strides_correct[[0, 1, 2]].idxmax(axis = 1) \n",
    "        #Appending the test subjects' true and predicted label for each fold to compute subject-wise confusion matrix \n",
    "        test_subjects_true_predicted_labels = test_subjects_true_predicted_labels.append(proportion_strides_correct)          \n",
    "            \n",
    "        #Person wise metrics for each fold \n",
    "        person_acc.append(accuracy_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label']))\n",
    "        person_p.append(precision_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label'], \\\n",
    "                                       average = 'macro'))\n",
    "        person_r.append(recall_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label'], \\\n",
    "                                    average = 'macro'))\n",
    "        person_f1.append(f1_score(proportion_strides_correct['Predicted Label'], proportion_strides_correct['True Label'], \\\n",
    "                                  average = 'macro'))\n",
    "        person_auc.append(roc_auc_score(proportion_strides_correct['True Label'], proportion_strides_correct[[0, 1, 2]], \\\n",
    "                                        multi_class = 'ovo', average= 'macro'))\n",
    "\n",
    "    #Mean and standard deviation for person-based metrics \n",
    "    person_means = [np.mean(person_acc), np.mean(person_p), np.mean(person_r), np.mean(person_f1), np.mean(person_auc)]\n",
    "    person_stds = [np.std(person_acc), np.std(person_p), np.std(person_r), np.std(person_f1), np.std(person_auc)]\n",
    "    print('Person-based model performance (mean): ', person_means)\n",
    "    print('Person-based model performance (standard deviation): ', person_stds)\n",
    "    \n",
    "    #Saving the stride and person wise true and predicted labels for calculating the \n",
    "    #stride and subject wise confusion matrix for each model\n",
    "    test_strides_true_predicted_labels.to_csv(results_path+ framework + '\\\\stride_wise_predictions_' + \\\n",
    "                                      str(model_name) + '_' + framework + '.csv')\n",
    "    test_subjects_true_predicted_labels.to_csv(results_path+ framework + '\\\\person_wise_predictions_' + \\\n",
    "                                      str(model_name) + '_' + framework + '.csv')\n",
    "    \n",
    "    return test_subjects_true_predicted_labels, [stride_metrics_mean, stride_metrics_std, person_means, person_stds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true,y_pred):\n",
    "    '''\n",
    "    Returns the accuracy \n",
    "    Saves the true and predicted labels for training and test sets\n",
    "    '''\n",
    "    global yoriginal, ypredicted\n",
    "    yoriginal.append(y_true)\n",
    "    ypredicted.append(y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do not use LDA/QDA since our features are not normally distributed \n",
    "def models(X, Y, model_name = 'random_forest', framework = 'W'):\n",
    "    '''\n",
    "    Arguments:\n",
    "    X, Y, PID groups so that strides of each person are either in training or in testing set\n",
    "    model: model_name, framework we wish to run the code for\n",
    "    Returns: predicted probabilities and labels for each class, stride and subject based evaluation metrics \n",
    "    '''\n",
    "    Y_ = Y['label'] #Dropping the PID\n",
    "    groups_ = Y['PID']\n",
    "    #We use stratified group K-fold to sample our strides data\n",
    "    gkf = StratifiedGroupKFold(n_splits=5) \n",
    "    scores={'accuracy': make_scorer(acc), 'precision':make_scorer(precision_score, average = 'macro'), \\\n",
    "            'recall':make_scorer(recall_score, average = 'macro'), 'f1': make_scorer(f1_score, average = 'macro'), \\\n",
    "            'auc': make_scorer(roc_auc_score, average = 'macro', multi_class = 'ovo', needs_proba=True)}\n",
    "    if(model_name == 'random_forest'): #Random Forest\n",
    "        grid = {\n",
    "       'randomforestclassifier__n_estimators': [40,45,50],\\\n",
    "       'randomforestclassifier__max_depth' : [15,20,25,None],\\\n",
    "       'randomforestclassifier__class_weight': [None, 'balanced'],\\\n",
    "       'randomforestclassifier__max_features': ['auto','sqrt','log2', None],\\\n",
    "       'randomforestclassifier__min_samples_leaf':[1,2,0.1,0.05]\n",
    "        }\n",
    "        #For z-score scaling on training and use calculated coefficients on test set\n",
    "        rf_grid = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=0))\n",
    "        grid_search = GridSearchCV(rf_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'adaboost'): #Adaboost\n",
    "        ada_grid = make_pipeline(StandardScaler(), AdaBoostClassifier(random_state=0))\n",
    "        grid = {\n",
    "        'adaboostclassifier__n_estimators':[50, 75, 100, 125, 150],\\\n",
    "        'adaboostclassifier__learning_rate':[0.01,.1, 1, 1.5, 2]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(ada_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "        \n",
    "    if(model_name == 'kernel_svm'): #RBF SVM\n",
    "        svc_grid = make_pipeline(StandardScaler(), SVC(kernel = 'rbf', probability=True, random_state=0))\n",
    "        grid = {\n",
    "        'svc__gamma':[0.0001, 0.001, 0.1, 1, 10, ]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(svc_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "\n",
    "    if(model_name == 'gbm'): #GBM\n",
    "        gbm_grid = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=0))\n",
    "        grid = {\n",
    "        'gradientboostingclassifier__learning_rate':[0.15,0.1,0.05], \\\n",
    "        'gradientboostingclassifier__n_estimators':[50, 100, 150],\\\n",
    "        'gradientboostingclassifier__max_depth':[2,4,7],\\\n",
    "        'gradientboostingclassifier__min_samples_split':[2,4], \\\n",
    "        'gradientboostingclassifier__min_samples_leaf':[1,3],\\\n",
    "        'gradientboostingclassifier__max_features':['auto','sqrt','log2', None],\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(gbm_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name=='xgboost'): #Xgboost\n",
    "        xgb_grid = make_pipeline(StandardScaler(), xgboost.XGBClassifier(random_state=0))\n",
    "        grid = {\n",
    "            'xgbclassifier__min_child_weight': [1, 5],\\\n",
    "            'xgbclassifier__gamma': [0.1, 0.5, 1, 1.5, 2],\\\n",
    "            'xgbclassifier__subsample': [0.6, 0.8, 1.0],\\\n",
    "            'xgbclassifier__colsample_bytree': [0.6, 0.8, 1.0],\\\n",
    "            'xgbclassifier__max_depth': [5, 7, 8]\n",
    "        }\n",
    "        grid_search = GridSearchCV(xgb_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'knn'): #KNN\n",
    "        knn_grid = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "        grid = {\n",
    "            'kneighborsclassifier__n_neighbors': [1, 3, 4, 5, 10],\\\n",
    "            'kneighborsclassifier__p': [1, 2, 3, 4, 5]\\\n",
    "        }\n",
    "        grid_search = GridSearchCV(knn_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "        \n",
    "    if(model_name == 'decision_tree'): #Decision Tree\n",
    "        dec_grid = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=0))\n",
    "        #For z-score scaling on training and use calculated coefficients on test set\n",
    "        grid = {'decisiontreeclassifier__min_samples_split': range(2, 50)}\n",
    "        grid_search = GridSearchCV(dec_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "\n",
    "    if(model_name == 'linear_svm'): #Linear SVM\n",
    "        lsvm_grid = make_pipeline(StandardScaler(), SVC(kernel = 'linear', probability=True, random_state=0)) #LinearSVC(random_state=0, probability= True))\n",
    "        grid = {\n",
    "            'svc__gamma':[0.0001, 0.001, 0.1, 1, 10, ]\\\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(lsvm_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'logistic_regression'): #Logistic regression\n",
    "        lr_grid = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "        grid = {\n",
    "            'logisticregression__random_state': [0]}\n",
    "            \n",
    "        grid_search = GridSearchCV(lr_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    \n",
    "    if(model_name == 'mlp'):\n",
    "        mlp_grid = make_pipeline(StandardScaler(), MLPClassifier(random_state = 0, activation='relu', solver='adam',\\\n",
    "                                                       learning_rate = 'adaptive', learning_rate_init=0.001, \n",
    "                                                        shuffle=False, max_iter = 200))\n",
    "        grid = {\n",
    "            'mlpclassifier__hidden_layer_sizes': [(128, 8, 8, 128, 32), (50, 50, 50, 50, 50, 50, 150, 100, 10), \n",
    "                                  (50, 50, 50, 50, 50, 60, 30, 20, 50), (50, 50, 50, 50, 50, 150, 10, 60, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 50, 10, 5), (50, 50, 50, 50, 50, 5, 50, 150, 150),\n",
    "                                  (50, 50, 50, 50, 50, 5, 30, 50, 20), (50, 50, 50, 50, 10, 150, 20, 20, 30),\n",
    "                                  (50, 50, 50, 50, 30, 150, 100, 20, 100), (50, 50, 50, 50, 30, 5, 100, 20, 100),\n",
    "                                  (50, 50, 50, 50, 60, 50, 50, 60, 60), (50, 50, 50, 50, 20, 50, 60, 20, 20),\n",
    "                                  (50, 50, 50, 10, 50, 10, 150, 60, 150), (50, 50, 50, 10, 50, 150, 30, 150, 5),\n",
    "                                  (50, 50, 50, 10, 50, 20, 150, 5, 10), (50, 50, 50, 10, 150, 50, 20, 20, 100), \n",
    "                                  (50, 50, 50, 30, 100, 5, 30, 150, 30), (50, 50, 50, 50, 100, 150, 100, 200), \n",
    "                                  (50, 50, 50, 5, 5, 100, 100, 150), (50, 50, 5, 50, 200, 100, 150, 5), \n",
    "                                  (50, 50, 5, 5, 200, 100, 50, 30), (50, 50, 5, 10, 5, 200, 200, 10), \n",
    "                                  (50, 50, 5, 30, 5, 5, 50, 10), (50, 50, 5, 200, 50, 5, 5, 50), \n",
    "                                  (50, 50,50, 5, 5, 100, 100, 150), (5, 5, 5, 5, 5, 100, 50, 5, 50, 50), \n",
    "                                  (5, 5, 5, 5, 5, 100, 20, 100, 30, 30), (5, 5, 5, 5, 5, 20, 20, 5, 30, 100), \n",
    "                                  (5, 5, 5, 5, 5, 20, 20, 100, 10, 10), (5, 5, 5, 5, 10, 10, 30, 50, 10, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 30, 30, 30, 10), (5, 5, 5, 5, 10, 100, 50, 10, 50, 10), \n",
    "                                  (5, 5, 5, 5, 10, 100, 20, 100, 30, 5), (5, 5, 5, 5, 30, 5, 20, 30, 100, 50), \n",
    "                                  (5, 5, 5, 5, 30, 100, 20, 50, 20, 30), (5, 5, 5, 5, 50, 30, 5, 50, 10, 100), \n",
    "                                  (21, 21, 7, 84, 21, 84, 84), (21, 21, 5, 42, 42, 7, 42), (21, 84, 7, 7, 7, 84, 5), \n",
    "                                  (21, 7, 84, 5, 5, 21, 120), (42, 5, 21, 21, 21, 5, 120), (42, 5, 42, 84, 7, 120, 84), \n",
    "                                  (50, 100, 10, 5, 100, 25), (10, 10, 25, 50, 25, 5), (50, 50, 50, 50, 50, 20, 30, 100, 60)]\n",
    "\n",
    "        }\n",
    "        grid_search = GridSearchCV(mlp_grid, param_grid=grid, scoring=scores\\\n",
    "                           , n_jobs = 1, cv=gkf.split(X, Y_, groups=groups_), refit=False)\n",
    "    grid_search.fit(X, Y_, groups=groups_) #Fitting on the training set to find the optimal hyperparameters \n",
    "    test_subjects_true_predicted_labels, stride_person_metrics = evaluate(grid_search, Y, yoriginal, ypredicted, framework, model_name)\n",
    "    return test_subjects_true_predicted_labels, stride_person_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curves \n",
    "def plot_ROC(ml_model, test_set_true_predicted_labels, framework):\n",
    "    '''\n",
    "    Function to plot the ROC curve and confusion matrix for model given in ml_model name \n",
    "    Input: ml_models (name of models to plot the ROC for),  test_Y (true test set labels with PID), \n",
    "        predicted_probs_person (predicted test set probabilities for all 3 classes - HOA/MS/PD), framework (WtoWT / VBWtoVBWT)\n",
    "    Plots and saves the ROC curve with individual class-wise plots and micro/macro average plots \n",
    "    '''\n",
    "    n_classes = 3 #HOA/MS/PD\n",
    "    cohort = ['HOA', 'MS', 'PD']\n",
    "    ml_model_names = {'random_forest': 'RF', 'adaboost': 'AdaBoost', 'kernel_svm': 'RBF SVM', 'gbm': 'GBM', \\\n",
    "                  'xgboost': 'Xgboost', 'knn': 'KNN', 'decision_tree': 'DT',  'linear_svm': 'LSVM', \n",
    "             'logistic_regression': 'LR', 'mlp':'MLP'}\n",
    "\n",
    "    #Binarizing/getting dummies for the true labels i.e. class 1 is represented as 0, 1, 0\n",
    "    test_features_binarize = pd.get_dummies(test_set_true_predicted_labels['True Label'].values)     \n",
    "    sns.despine(offset=0)\n",
    "    linestyles = ['-', '-', '-', '-.', '--', '-', '--', '-', '--']\n",
    "    colors = ['b', 'magenta', 'cyan', 'g',  'red', 'violet', 'lime', 'grey', 'pink']\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, sharex=True, sharey = True, figsize=(6, 4.5))\n",
    "    axes.plot([0, 1], [0, 1], linestyle='--', label='Majority (AUC = 0.5)', linewidth = 3, color = 'k')\n",
    "    # person-based prediction probabilities for class 0: HOA, 1: MS, 2: PD\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    tpr, fpr, roc_auc = dict(), dict(), dict()\n",
    "    for i in range(n_classes): #n_classes = 3\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_features_binarize.iloc[:, i], test_set_true_predicted_labels.loc[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        #Plotting the ROCs for the three classes separately\n",
    "        axes.plot(fpr[i], tpr[i], label = cohort[i] +' ROC (AUC = '+ str(round(roc_auc[i], 3))\n",
    "            +')', linewidth = 3, alpha = 0.8, linestyle = linestyles[i], color = colors[i])\n",
    "        \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_features_binarize.values.ravel(),\\\n",
    "                                              test_set_true_predicted_labels[[0, 1, 2]].values.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    #Plotting the micro average ROC \n",
    "    axes.plot(fpr[\"micro\"], tpr[\"micro\"], label= 'micro average ROC (AUC = '+ str(round(roc_auc[\"micro\"], 3))\n",
    "            +')', linewidth = 3, alpha = 0.8, linestyle = linestyles[3], color = colors[3])\n",
    "    \n",
    "    #Compute the macro-average ROC curve and AUC value\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)])) # First aggregate all false positive rates\n",
    "    mean_tpr = np.zeros_like(all_fpr) # Then interpolate all ROC curves at this points\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes  # Finally average it and compute AUC\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    #Macro average AUC of ROC value \n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])    \n",
    "    #Plotting the macro average AUC\n",
    "    axes.plot(fpr[\"macro\"], tpr[\"macro\"], label= 'macro average ROC (AUC = '+ str(round(roc_auc[\"macro\"], 3))\n",
    "        +')', linewidth = 3, alpha = 0.8, linestyle = linestyles[4], color = colors[4])\n",
    "    \n",
    "    axes.set_ylabel('True Positive Rate')\n",
    "    axes.set_title('Subject generalization '+framework + ' '+ ml_model_names[ml_model])\n",
    "    plt.legend()\n",
    "    # axes[1].legend(loc='upper center', bbox_to_anchor=(1.27, 1), ncol=1)\n",
    "\n",
    "    axes.set_xlabel('False Positive Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_path + framework+'\\\\ROC_subject_generalize_' + framework + '_'+ ml_model+ '.png', dpi = 350)\n",
    "    plt.show()\n",
    "    \n",
    "    #Plotting and saving the subject wise confusion matrix \n",
    "    plt.figure()\n",
    "    confusion_matrix = pd.crosstab(test_set_true_predicted_labels['True Label'], test_set_true_predicted_labels['Predicted Label'], \\\n",
    "                                   rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
    "    sns.heatmap(confusion_matrix, annot=True, cmap=\"YlGnBu\")\n",
    "    plt.savefig(results_path + framework+'\\\\CFmatrix_subject_generalize_' + framework + '_'+ ml_model+ '.png', dpi = 350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ml_models(ml_models, X, Y, framework):\n",
    "    '''\n",
    "    Function to run the ML models for the required framework\n",
    "    Arguments: names of ml_models, X, Y, framework \n",
    "    Returns and saves .csv for evaluation metrics and tprs/fprs/rauc for the ROC curves \n",
    "    '''\n",
    "    metrics = pd.DataFrame(columns = ml_models) #Dataframe to store accuracies for each ML model for raw data \n",
    "    for ml_model in ml_models:\n",
    "        print (ml_model)\n",
    "        global yoriginal, ypredicted\n",
    "        yoriginal = []\n",
    "        ypredicted = []\n",
    "        test_subjects_true_predicted_labels, stride_person_metrics = models(X, Y, ml_model, framework)\n",
    "        metrics[ml_model] = sum(stride_person_metrics, [])\n",
    "        plot_ROC(ml_model, test_subjects_true_predicted_labels, framework)\n",
    "        print ('********************************')\n",
    "    metrics.index = ['stride_mean_accuracy', 'stride_mean_precision', 'stride_mean_recall', 'stride_mean_F1', \\\n",
    "                         'stride_mean_AUC', 'stride_std_accuracy', 'stride_std_precision', 'stride_std_recall', 'stride_std_F1', \\\n",
    "                         'stride_std_AUC','person_mean_accuracy', 'person_mean_precision', 'person_mean_recall', 'person_mean_F1',\\\n",
    "                         'person_mean_AUC', 'person_std_accuracy', 'person_std_precision', 'person_std_recall', 'person_std_F1',\\\n",
    "                         'person_std_AUC']  \n",
    "    #Saving the evaluation metrics and tprs/fprs/rauc for the ROC curves \n",
    "    metrics.to_csv(results_path+framework+'\\\\subject_generalize_'+framework+'_result_metrics.csv')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of subjects in trial W for cross validation: 32\n",
      "Number of subjects in trial W in each cohort:\n",
      " HOA    14\n",
      "MS     10\n",
      "PD      8\n",
      "Name: cohort, dtype: int64\n",
      "Strides in trial W for cross validation:  1651\n",
      "HOA, MS and PD strides in trial W:\n",
      " HOA    809\n",
      "PD     453\n",
      "MS     389\n",
      "Name: cohort, dtype: int64\n",
      "Imbalance ratio in trial W (controls:MS:PD)= 1:X:Y\n",
      " HOA    1.000000\n",
      "PD     0.559951\n",
      "MS     0.480841\n",
      "Name: cohort, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Trial W for the first framework of subject generalization\n",
    "trialW = data[data['scenario']=='W']\n",
    "print ('Original number of subjects in trial W for cross validation:', len(trialW['PID'].unique()))\n",
    "print ('Number of subjects in trial W in each cohort:\\n', trialW.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialW = shuffle(trialW, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X = trialW.drop(cols_to_drop, axis = 1)\n",
    "Y = trialW[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial W for cross validation: ', len(trialW))\n",
    "print ('HOA, MS and PD strides in trial W:\\n', trialW['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial W (controls:MS:PD)= 1:X:Y\\n', trialW['cohort'].value_counts()/trialW['cohort'].value_counts()['HOA'])\n",
    "\n",
    "#Defining the framework of interest\n",
    "framework = 'W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest\n"
     ]
    }
   ],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics = run_ml_models(ml_models, X, Y, framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject generalization framework 2: walking while talking (WT) to classify strides and subjects of HOA/MS/PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial WT for the second framework of subject generalization\n",
    "trialWT = data[data['scenario']=='WT']\n",
    "print ('Original number of subjects in trial WT for cross validation:', len(trialWT['PID'].unique()))\n",
    "print ('Number of subjects in trial WT in each cohort:\\n', trialWT.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialWT = shuffle(trialWT, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_WT = trialWT.drop(cols_to_drop, axis = 1)\n",
    "Y_WT = trialWT[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial WT for cross validation: ', len(trialWT))\n",
    "print ('HOA, MS and PD strides in trial WT:\\n', trialWT['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial WT (controls:MS:PD)= 1:X:Y\\n', trialWT['cohort'].value_counts()/trialWT['cohort'].value_counts()['HOA'])\n",
    "#Defining the framework of interest\n",
    "framework = 'WT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_WT = run_ml_models(ml_models, X_WT, Y_WT, framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_WT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject generalization framework 3: virtual beam walking (VBW) to classify strides and subjects of HOA/MS/PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial VBW for the third framework of subject generalization\n",
    "trialVBW = data[data['scenario']=='SLW']\n",
    "print ('Original number of subjects in trial VBW for cross validation:', len(trialVBW['PID'].unique()))\n",
    "print ('Number of subjects in trial VBW in each cohort:\\n', trialVBW.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialVBW = shuffle(trialVBW, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_VBW = trialVBW.drop(cols_to_drop, axis = 1)\n",
    "Y_VBW = trialVBW[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial VBW for cross validation: ', len(trialVBW))\n",
    "print ('HOA, MS and PD strides in trial VBW:\\n', trialVBW['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial VBW (controls:MS:PD)= 1:X:Y\\n', trialVBW['cohort'].value_counts()/trialVBW['cohort'].value_counts()['HOA'])\n",
    "#Defining the framework of interest\n",
    "framework = 'VBW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_VBW = run_ml_models(ml_models, X_VBW, Y_VBW, framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_VBW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject generalization framework 4: virtual beam walking while talking (VBWT) to classify strides and subjects of HOA/MS/PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial VBWT for the fourth framework of subject generalization\n",
    "trialVBWT = data[data['scenario']=='SLWT']\n",
    "print ('Original number of subjects in trial VBWT for cross validation:', len(trialVBWT['PID'].unique()))\n",
    "print ('Number of subjects in trial VBWT in each cohort:\\n', trialVBWT.groupby('PID').first()['cohort'].value_counts())\n",
    "\n",
    "cols_to_drop = ['PID', 'key', 'cohort', 'trial', 'scenario', 'video', 'stride_number', 'label']\n",
    "#Shuffling the cross validation stride data\n",
    "trialVBWT = shuffle(trialVBWT, random_state = 0)\n",
    "#CV for people generalize so no train-test split\n",
    "X_VBWT = trialVBWT.drop(cols_to_drop, axis = 1)\n",
    "Y_VBWT = trialVBWT[['PID', 'label']]\n",
    "\n",
    "#Total strides and imbalance of labels in the training and testing set\n",
    "#Training set \n",
    "print('Strides in trial VBWT for cross validation: ', len(trialVBWT))\n",
    "print ('HOA, MS and PD strides in trial VBWT:\\n', trialVBWT['cohort'].value_counts())\n",
    "print ('Imbalance ratio in trial VBWT (controls:MS:PD)= 1:X:Y\\n', trialVBWT['cohort'].value_counts()/trialVBWT['cohort'].value_counts()['HOA'])\n",
    "#Defining the framework of interest\n",
    "framework = 'VBWT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_models = ['random_forest', 'adaboost', 'kernel_svm', 'gbm', 'xgboost', 'knn', 'decision_tree',  'linear_svm', \n",
    "             'logistic_regression', 'mlp']\n",
    "metrics_VBWT = run_ml_models(ml_models, X_VBWT, Y_VBWT, framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_VBWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do!\n",
    "#ROC- Done \n",
    "#Confusion matrix files - Done\n",
    "#CF itself - Done\n",
    "#Saving all results to results folder - Done\n",
    "#Comments in utility functions - Done\n",
    "#micro macro weighted save all results \n",
    "#How can we compare different frameworks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
